{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TarefaBaggingPasting.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LPBnuryZh3M",
        "colab_type": "text"
      },
      "source": [
        "**1. Introdução**\n",
        "\n",
        "O objetivo deste trabalho é analisar um problema de ciência de dados com as técnicas de aprendizado de máquina de bagging e pasting. Para isso, será utilizado como exemplo o problema descrito na seção 2.3.3 apresentado em https://github.com/ivanovitchm/EEC1509_Machine_Learning_2019_2/blob/master/Lesson%2308/Lesson_08_Ensemble_Learning_I.ipynb.\n",
        "\n",
        "A base de dados utilizada consite em um banco de dados sobre a renda de americanos no censo do ano de 1994.\n",
        "\n",
        "A maior parte do código fonte apresentado a seguir foi originalmente obtido do artigo do link acima. O objetivo deste trabalho é realizar a personalização do pipeline apresentado e seus impactos no desempenho do modelo e principalmente em relação ao overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bGVPk0LkwmX",
        "colab_type": "text"
      },
      "source": [
        "**2. Analisando a base de dados**\n",
        "\n",
        "O primeiro passo é analisar como a base de dados está estruturada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otn2QwQILmvM",
        "colab_type": "code",
        "outputId": "0ba5c8d6-1fe3-4f3b-cf0d-0e28a177c58d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "# Exibe o início do arquivo.\n",
        "!head -n 5 income.csv\n",
        "\n",
        "# Verifica o número de linhas do arquivo.\n",
        "!wc -l income.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age,workclass,fnlwgt,education,education_num,marital_status,occupation,relationship,race,sex,capital_gain,capital_loss,hours_per_week,native_country,high_income\n",
            "39, State-gov, 77516, Bachelors, 13, Never-married, Adm-clerical, Not-in-family, White, Male, 2174, 0, 40, United-States, <=50K\n",
            "50, Self-emp-not-inc, 83311, Bachelors, 13, Married-civ-spouse, Exec-managerial, Husband, White, Male, 0, 0, 13, United-States, <=50K\n",
            "38, Private, 215646, HS-grad, 9, Divorced, Handlers-cleaners, Not-in-family, White, Male, 0, 0, 40, United-States, <=50K\n",
            "53, Private, 234721, 11th, 7, Married-civ-spouse, Handlers-cleaners, Husband, Black, Male, 0, 0, 40, United-States, <=50K\n",
            "32562 income.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppnO1UsuLoeH",
        "colab_type": "text"
      },
      "source": [
        "Como o arquivo CSV está bem estruturado, ele pode ser lido utilizando Pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPRCnk5fl-25",
        "colab_type": "code",
        "outputId": "7457c158-26c7-4acf-90fa-8c3679c6a4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carrega a base de dados e exibe a sua estrutura inicial.\n",
        "income = pd.read_csv('income.csv', sep=',')\n",
        "income.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "      <th>high_income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age          workclass  fnlwgt  ... hours_per_week  native_country high_income\n",
              "0   39          State-gov   77516  ...             40   United-States       <=50K\n",
              "1   50   Self-emp-not-inc   83311  ...             13   United-States       <=50K\n",
              "2   38            Private  215646  ...             40   United-States       <=50K\n",
              "3   53            Private  234721  ...             40   United-States       <=50K\n",
              "4   28            Private  338409  ...             40            Cuba       <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Sv7QUdenWlS",
        "colab_type": "code",
        "outputId": "0fd882ed-9c11-4812-b096-22fe05086f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "# Verifica se existe algum valor nulo.\n",
        "income.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32561 entries, 0 to 32560\n",
            "Data columns (total 15 columns):\n",
            "age               32561 non-null int64\n",
            "workclass         32561 non-null object\n",
            "fnlwgt            32561 non-null int64\n",
            "education         32561 non-null object\n",
            "education_num     32561 non-null int64\n",
            "marital_status    32561 non-null object\n",
            "occupation        32561 non-null object\n",
            "relationship      32561 non-null object\n",
            "race              32561 non-null object\n",
            "sex               32561 non-null object\n",
            "capital_gain      32561 non-null int64\n",
            "capital_loss      32561 non-null int64\n",
            "hours_per_week    32561 non-null int64\n",
            "native_country    32561 non-null object\n",
            "high_income       32561 non-null object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 3.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67GXWxLWmPsd",
        "colab_type": "text"
      },
      "source": [
        "Como se vê acima, a base de dados possui 32561 entradas e nenhum valor não nulo. Porém, 9 colunas são categóricas - não numéricas - e precisam ser pré-processadas de maneira diferente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIP13Q82qBiV",
        "colab_type": "text"
      },
      "source": [
        "**3. Pré-processamento da base de dados**\n",
        "\n",
        "O primeiro passo é converter a coluna alvo (o que nosso modelo pretende prever para categórica, isto é, as faixas de renda do invíduo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6nxn1k0m0Ji",
        "colab_type": "code",
        "outputId": "6f4ee4b2-624c-4211-d0fc-86fa88c8471f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "col = pd.Categorical(income.high_income)\n",
        "income[\"high_income\"] = col.codes\n",
        "print(col)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<=50K, <=50K, <=50K, <=50K, <=50K, ..., <=50K, >50K, <=50K, <=50K, >50K]\n",
            "Length: 32561\n",
            "Categories (2, object): [<=50K, >50K]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt696jjroCLq",
        "colab_type": "text"
      },
      "source": [
        "Como se vê acima, só existem duas categorias: menour ou igual a 50k ou maior que 50k USD e estas foram convertidas para 0 ou 1, respectivamente.\n",
        "\n",
        "As classes abaixo são definidas para tratar as demais colunas (ambas copiadas do artigo original).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcEDWRO9opEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "#Custom Transformer that extracts columns passed as argument to its constructor \n",
        "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
        "    #Class Constructor \n",
        "    def __init__( self, feature_names ):\n",
        "        self.feature_names = feature_names \n",
        "    \n",
        "    #Return self nothing else to do here    \n",
        "    def fit( self, X, y = None ):\n",
        "        return self \n",
        "    \n",
        "    #Method that describes what we need this transformer to do\n",
        "    def transform( self, X, y = None ):\n",
        "        return X[ self.feature_names ]\n",
        "\n",
        "#converts certain features to categorical\n",
        "class CategoricalTransformer( BaseEstimator, TransformerMixin ):\n",
        "  #Class constructor method that takes a boolean as its argument\n",
        "  def __init__(self, new_features=True):\n",
        "    self.new_features = new_features\n",
        "\n",
        "  #Return self nothing else to do here    \n",
        "  def fit( self, X, y = None ):\n",
        "    return self \n",
        "        \n",
        "  #Transformer method we wrote for this transformer \n",
        "  def transform(self, X , y = None ):\n",
        "    df = X.copy()\n",
        "    if self.new_features:\n",
        "      # Treat ? workclass as unknown\n",
        "      df['workclass']= df['workclass'].replace('?','Unknown') \n",
        "      # Two many category level, convert just US and Non-US\n",
        "      df.loc[df['native_country']!=' United-States','native_country'] = 'non_usa' \n",
        "\n",
        "    # convert columns to categorical\n",
        "    for name in df.columns.to_list():\n",
        "      col = pd.Categorical(df[name])\n",
        "      df[name] = col.codes\n",
        "    \n",
        "    #returns numpy array\n",
        "    return df        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tjHocCXpMUa",
        "colab_type": "text"
      },
      "source": [
        "Para validar as classes acima:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IGfysjjpPIl",
        "colab_type": "code",
        "outputId": "d59bfeb4-cc0b-46f2-9dc7-e05c69eb0b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "model = CategoricalTransformer(new_features=True)\n",
        "df = model.transform(income.drop(labels=[\"high_income\"],axis=1))\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "      <th>native_country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>2671</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33</td>\n",
              "      <td>6</td>\n",
              "      <td>2926</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>14086</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36</td>\n",
              "      <td>4</td>\n",
              "      <td>15336</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>19355</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  workclass  fnlwgt  ...  capital_loss  hours_per_week  native_country\n",
              "0   22          7    2671  ...             0              39               0\n",
              "1   33          6    2926  ...             0              12               0\n",
              "2   21          4   14086  ...             0              39               0\n",
              "3   36          4   15336  ...             0              39               0\n",
              "4   11          4   19355  ...             0              39               1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CQY7Y-1pg-7",
        "colab_type": "code",
        "outputId": "1fc0e2ea-f547-4cf2-a8a5-7ab9a36b3f2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "model = FeatureSelector(income.select_dtypes(\"object\").columns.to_list())\n",
        "df = model.transform(income.drop(labels=[\"high_income\"],axis=1))\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>native_country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>State-gov</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Private</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Private</td>\n",
              "      <td>11th</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Private</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>Cuba</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           workclass   education  ...      sex  native_country\n",
              "0          State-gov   Bachelors  ...     Male   United-States\n",
              "1   Self-emp-not-inc   Bachelors  ...     Male   United-States\n",
              "2            Private     HS-grad  ...     Male   United-States\n",
              "3            Private        11th  ...     Male   United-States\n",
              "4            Private   Bachelors  ...   Female            Cuba\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Unq22rRpwAt",
        "colab_type": "text"
      },
      "source": [
        "Como se vê acima, ambas as classes serviram para pré-processar a base dados, tanto fazendo a conversão de variáveis não numérica para numéricas quanto para fazer a seleção das features com maior relevância."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3P1NpO3qYHo",
        "colab_type": "text"
      },
      "source": [
        "**Configuração do modelo de aprendizagem de máquina**\n",
        "\n",
        "Com a base de dados pré-processada, agora podemos criar o modelo de aprendizagem de máquina. Os parâmetros a seguir foram copiados do artigo original para posteriormente fazermos uma comparação na mudança dos hiperparâmetros do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc75SAE8q2ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score\n",
        "\n",
        "# global varibles\n",
        "seed = 42\n",
        "num_folds = 10\n",
        "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZDf8iL0rXA8",
        "colab_type": "text"
      },
      "source": [
        "O passo seguinte é separar o conjunto de teste e treinamento (também seguindo a mesma estrutura do artigo original)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9JkulQZrJT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split-out train/validation and test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(income.drop(labels=\"high_income\", axis=1),\n",
        "                                                    income[\"high_income\"],\n",
        "                                                    test_size=0.20,\n",
        "                                                    random_state=seed,\n",
        "                                                    shuffle=True,\n",
        "                                                    stratify=income[\"high_income\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G35iJOH7rv3I",
        "colab_type": "text"
      },
      "source": [
        "Com os conjuntos de treinamento e testes construídos, podemos finalmente definir os pipelines que processarão tanto as variáveis categóricas quanto numéricas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o27UHRH6r1qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Categrical features to pass down the categorical pipeline \n",
        "categorical_features = income.select_dtypes(\"object\").columns.to_list()\n",
        "\n",
        "# Numerical features to pass down the numerical pipeline \n",
        "numerical_features = income.select_dtypes(\"int64\").columns.to_list()\n",
        "\n",
        "# Defining the steps in the categorical pipeline \n",
        "categorical_pipeline = Pipeline(steps = [('cat_selector', FeatureSelector(categorical_features)),\n",
        "                                         ('cat_transformer', CategoricalTransformer())\n",
        "                                         ]\n",
        "                                )\n",
        "# Defining the steps in the numerical pipeline     \n",
        "numerical_pipeline = Pipeline(steps = [('num_selector', FeatureSelector(numerical_features)),\n",
        "                                       ('std_scaler', MinMaxScaler()) \n",
        "                                       ]\n",
        "                              )\n",
        "\n",
        "# Combining numerical and categorical piepline into one full big pipeline horizontally \n",
        "# using FeatureUnion\n",
        "full_pipeline_preprocessing = FeatureUnion(transformer_list = [('categorical_pipeline', categorical_pipeline),\n",
        "                                                               ('numerical_pipeline', numerical_pipeline)\n",
        "                                                               ]\n",
        "                                           )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4zBA3f4sNx1",
        "colab_type": "text"
      },
      "source": [
        "Para validar como os pipelines acima puderam processar o dataframe como um todo, abaixo será exibido o seu formato final, em que todos os valores das features são numéricos e devidamente normalizados para escalas de mesma ordem de grandeza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkV2G-9rsdQw",
        "colab_type": "code",
        "outputId": "455d3c4f-7eb6-4a69-964f-125c78a8b032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "new_data = full_pipeline_preprocessing.fit_transform(X_train)\n",
        "new_data_df = pd.DataFrame(new_data,columns = categorical_features + numerical_features)\n",
        "new_data_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>workclass</th>\n",
              "      <th>education</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>native_country</th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education_num</th>\n",
              "      <th>capital_gain</th>\n",
              "      <th>capital_loss</th>\n",
              "      <th>hours_per_week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.205479</td>\n",
              "      <td>0.016928</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.448980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.356164</td>\n",
              "      <td>0.060896</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.448980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.041096</td>\n",
              "      <td>0.074679</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.275510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.315068</td>\n",
              "      <td>0.008474</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.068491</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.095890</td>\n",
              "      <td>0.069037</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   workclass  education  ...  capital_loss  hours_per_week\n",
              "0        4.0        9.0  ...           0.0        0.448980\n",
              "1        4.0       12.0  ...           0.0        0.448980\n",
              "2        0.0       11.0  ...           0.0        0.275510\n",
              "3        2.0       15.0  ...           0.0        0.397959\n",
              "4        4.0        9.0  ...           0.0        0.397959\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruRmL9f3s0oy",
        "colab_type": "text"
      },
      "source": [
        "**4. Escolha do modelo de aprendizagem de máquina**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pr1r36DtDT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# The full pipeline as a step in another pipeline with an estimator as the final step\n",
        "pipe = Pipeline(steps = [('full_pipeline', full_pipeline_preprocessing),\n",
        "                         (\"fs\", SelectKBest()),\n",
        "                         (\"clf\", RandomForestClassifier())])\n",
        "\n",
        "# create a dictionary with the hyperparameters\n",
        "# 12 x num_fold + 120 x num_folds = 1320 models =]\n",
        "# 50min \n",
        "search_space = [\n",
        "                {\"clf\": [DecisionTreeClassifier()],\n",
        "                 \"clf__criterion\": [\"gini\", \"entropy\"],\n",
        "                 \"clf__splitter\": [\"best\", \"random\"],\n",
        "                 \"clf__random_state\": [seed],\n",
        "                 \"fs__score_func\": [chi2],\n",
        "                 \"fs__k\": [4, 6, 8]},\n",
        "                {\"clf\":[RandomForestClassifier()],\n",
        "                 \"clf__n_estimators\": [100,200,300,400],\n",
        "                 \"clf__criterion\": [\"gini\",\"entropy\"],\n",
        "                 \"clf__max_leaf_nodes\": [4,16,32,64,128],\n",
        "                 \"clf__random_state\": [seed],\n",
        "                 \"fs__score_func\":[chi2],\n",
        "                 \"fs__k\":[4,6,8]}]\n",
        "\n",
        "# create grid search\n",
        "kfold = KFold(n_splits=num_folds,random_state=seed)\n",
        "\n",
        "# return_train_score=True\n",
        "# official documentation: \"computing the scores on the training set can be\n",
        "# computationally expensive and is not strictly required to\n",
        "# select the parameters that yield the best generalization performance\".\n",
        "grid = GridSearchCV(estimator=pipe, \n",
        "                    param_grid=search_space,\n",
        "                    cv=kfold,\n",
        "                    scoring=scoring,\n",
        "                    return_train_score=True,\n",
        "                    n_jobs=-1,\n",
        "                    refit=\"AUC\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQj2VU2JvhDR",
        "colab_type": "text"
      },
      "source": [
        "Como o treinamento do modelo acima é bastante custoso, o professor já disponibilizou o arquivo com os valores do treinamento. Logo, ele pode ser ignorado para economizar tempo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw6C6Wn9voIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Realize o treinamento somente se o arquivo com treinamento prévio não for encontrado.\n",
        "import pickle\n",
        "\n",
        "try:\n",
        "  best_model = pickle.load(open('pipe.pkl', 'rb'))\n",
        "except:\n",
        "  best_model = grid.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU7TFYzawrOQ",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, exibe o desempenho do modelo treinado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNFYcJvuwvYB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "outputId": "50bc4053-a27c-4e36-aa71-16944e1a0047"
      },
      "source": [
        "print(\"Best: %f using %s\" % (best_model.best_score_, best_model.best_params_))\n",
        "\n",
        "result = pd.DataFrame(best_model.cv_results_)\n",
        "result.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.902703 using {'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
            "                       max_depth=None, max_features='auto', max_leaf_nodes=128,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
            "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
            "                       warm_start=False), 'clf__criterion': 'entropy', 'clf__max_leaf_nodes': 128, 'clf__n_estimators': 200, 'clf__random_state': 42, 'fs__k': 8, 'fs__score_func': <function chi2 at 0x7faf2197eb70>}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_clf</th>\n",
              "      <th>param_clf__criterion</th>\n",
              "      <th>param_clf__random_state</th>\n",
              "      <th>param_clf__splitter</th>\n",
              "      <th>param_fs__k</th>\n",
              "      <th>param_fs__score_func</th>\n",
              "      <th>param_clf__max_leaf_nodes</th>\n",
              "      <th>param_clf__n_estimators</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_AUC</th>\n",
              "      <th>split1_test_AUC</th>\n",
              "      <th>split2_test_AUC</th>\n",
              "      <th>split3_test_AUC</th>\n",
              "      <th>split4_test_AUC</th>\n",
              "      <th>split5_test_AUC</th>\n",
              "      <th>split6_test_AUC</th>\n",
              "      <th>split7_test_AUC</th>\n",
              "      <th>split8_test_AUC</th>\n",
              "      <th>split9_test_AUC</th>\n",
              "      <th>mean_test_AUC</th>\n",
              "      <th>std_test_AUC</th>\n",
              "      <th>rank_test_AUC</th>\n",
              "      <th>split0_train_AUC</th>\n",
              "      <th>split1_train_AUC</th>\n",
              "      <th>split2_train_AUC</th>\n",
              "      <th>split3_train_AUC</th>\n",
              "      <th>split4_train_AUC</th>\n",
              "      <th>split5_train_AUC</th>\n",
              "      <th>split6_train_AUC</th>\n",
              "      <th>split7_train_AUC</th>\n",
              "      <th>split8_train_AUC</th>\n",
              "      <th>split9_train_AUC</th>\n",
              "      <th>mean_train_AUC</th>\n",
              "      <th>std_train_AUC</th>\n",
              "      <th>split0_test_Accuracy</th>\n",
              "      <th>split1_test_Accuracy</th>\n",
              "      <th>split2_test_Accuracy</th>\n",
              "      <th>split3_test_Accuracy</th>\n",
              "      <th>split4_test_Accuracy</th>\n",
              "      <th>split5_test_Accuracy</th>\n",
              "      <th>split6_test_Accuracy</th>\n",
              "      <th>split7_test_Accuracy</th>\n",
              "      <th>split8_test_Accuracy</th>\n",
              "      <th>split9_test_Accuracy</th>\n",
              "      <th>mean_test_Accuracy</th>\n",
              "      <th>std_test_Accuracy</th>\n",
              "      <th>rank_test_Accuracy</th>\n",
              "      <th>split0_train_Accuracy</th>\n",
              "      <th>split1_train_Accuracy</th>\n",
              "      <th>split2_train_Accuracy</th>\n",
              "      <th>split3_train_Accuracy</th>\n",
              "      <th>split4_train_Accuracy</th>\n",
              "      <th>split5_train_Accuracy</th>\n",
              "      <th>split6_train_Accuracy</th>\n",
              "      <th>split7_train_Accuracy</th>\n",
              "      <th>split8_train_Accuracy</th>\n",
              "      <th>split9_train_Accuracy</th>\n",
              "      <th>mean_train_Accuracy</th>\n",
              "      <th>std_train_Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.094254</td>\n",
              "      <td>0.004465</td>\n",
              "      <td>0.052384</td>\n",
              "      <td>0.000343</td>\n",
              "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
              "      <td>gini</td>\n",
              "      <td>42</td>\n",
              "      <td>best</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;function chi2 at 0x7faf2197eb70&gt;</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'clf': DecisionTreeClassifier(class_weight=No...</td>\n",
              "      <td>0.879737</td>\n",
              "      <td>0.770063</td>\n",
              "      <td>0.890067</td>\n",
              "      <td>0.754662</td>\n",
              "      <td>0.860297</td>\n",
              "      <td>0.894153</td>\n",
              "      <td>0.841077</td>\n",
              "      <td>0.829657</td>\n",
              "      <td>0.823056</td>\n",
              "      <td>0.830986</td>\n",
              "      <td>0.837376</td>\n",
              "      <td>0.044736</td>\n",
              "      <td>115</td>\n",
              "      <td>0.899191</td>\n",
              "      <td>0.898719</td>\n",
              "      <td>0.897951</td>\n",
              "      <td>0.898341</td>\n",
              "      <td>0.842931</td>\n",
              "      <td>0.898022</td>\n",
              "      <td>0.845008</td>\n",
              "      <td>0.846032</td>\n",
              "      <td>0.846578</td>\n",
              "      <td>0.844377</td>\n",
              "      <td>0.871715</td>\n",
              "      <td>0.026747</td>\n",
              "      <td>0.840307</td>\n",
              "      <td>0.785797</td>\n",
              "      <td>0.847601</td>\n",
              "      <td>0.779655</td>\n",
              "      <td>0.812668</td>\n",
              "      <td>0.849136</td>\n",
              "      <td>0.819194</td>\n",
              "      <td>0.810365</td>\n",
              "      <td>0.787634</td>\n",
              "      <td>0.807220</td>\n",
              "      <td>0.813959</td>\n",
              "      <td>0.024112</td>\n",
              "      <td>77</td>\n",
              "      <td>0.848867</td>\n",
              "      <td>0.848569</td>\n",
              "      <td>0.848057</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>0.809410</td>\n",
              "      <td>0.848057</td>\n",
              "      <td>0.808642</td>\n",
              "      <td>0.809623</td>\n",
              "      <td>0.812105</td>\n",
              "      <td>0.808778</td>\n",
              "      <td>0.829034</td>\n",
              "      <td>0.019343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.107457</td>\n",
              "      <td>0.005159</td>\n",
              "      <td>0.054094</td>\n",
              "      <td>0.001872</td>\n",
              "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
              "      <td>gini</td>\n",
              "      <td>42</td>\n",
              "      <td>best</td>\n",
              "      <td>6</td>\n",
              "      <td>&lt;function chi2 at 0x7faf2197eb70&gt;</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'clf': DecisionTreeClassifier(class_weight=No...</td>\n",
              "      <td>0.882060</td>\n",
              "      <td>0.795158</td>\n",
              "      <td>0.900740</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.900339</td>\n",
              "      <td>0.902825</td>\n",
              "      <td>0.785493</td>\n",
              "      <td>0.778393</td>\n",
              "      <td>0.795487</td>\n",
              "      <td>0.767909</td>\n",
              "      <td>0.829567</td>\n",
              "      <td>0.055405</td>\n",
              "      <td>119</td>\n",
              "      <td>0.926336</td>\n",
              "      <td>0.916263</td>\n",
              "      <td>0.915367</td>\n",
              "      <td>0.915165</td>\n",
              "      <td>0.925340</td>\n",
              "      <td>0.915251</td>\n",
              "      <td>0.915892</td>\n",
              "      <td>0.916630</td>\n",
              "      <td>0.927437</td>\n",
              "      <td>0.915181</td>\n",
              "      <td>0.918886</td>\n",
              "      <td>0.004944</td>\n",
              "      <td>0.844914</td>\n",
              "      <td>0.802687</td>\n",
              "      <td>0.852975</td>\n",
              "      <td>0.803071</td>\n",
              "      <td>0.851440</td>\n",
              "      <td>0.858349</td>\n",
              "      <td>0.804990</td>\n",
              "      <td>0.796929</td>\n",
              "      <td>0.797235</td>\n",
              "      <td>0.836406</td>\n",
              "      <td>0.824900</td>\n",
              "      <td>0.024614</td>\n",
              "      <td>60</td>\n",
              "      <td>0.863456</td>\n",
              "      <td>0.861067</td>\n",
              "      <td>0.860939</td>\n",
              "      <td>0.860299</td>\n",
              "      <td>0.863413</td>\n",
              "      <td>0.860257</td>\n",
              "      <td>0.859873</td>\n",
              "      <td>0.861281</td>\n",
              "      <td>0.864699</td>\n",
              "      <td>0.860561</td>\n",
              "      <td>0.861585</td>\n",
              "      <td>0.001572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.140714</td>\n",
              "      <td>0.005217</td>\n",
              "      <td>0.059645</td>\n",
              "      <td>0.010914</td>\n",
              "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
              "      <td>gini</td>\n",
              "      <td>42</td>\n",
              "      <td>best</td>\n",
              "      <td>8</td>\n",
              "      <td>&lt;function chi2 at 0x7faf2197eb70&gt;</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'clf': DecisionTreeClassifier(class_weight=No...</td>\n",
              "      <td>0.832547</td>\n",
              "      <td>0.754089</td>\n",
              "      <td>0.820625</td>\n",
              "      <td>0.772732</td>\n",
              "      <td>0.824723</td>\n",
              "      <td>0.821800</td>\n",
              "      <td>0.748504</td>\n",
              "      <td>0.744559</td>\n",
              "      <td>0.760581</td>\n",
              "      <td>0.810092</td>\n",
              "      <td>0.789025</td>\n",
              "      <td>0.034058</td>\n",
              "      <td>131</td>\n",
              "      <td>0.980977</td>\n",
              "      <td>0.981498</td>\n",
              "      <td>0.981194</td>\n",
              "      <td>0.981385</td>\n",
              "      <td>0.981547</td>\n",
              "      <td>0.981339</td>\n",
              "      <td>0.981833</td>\n",
              "      <td>0.981429</td>\n",
              "      <td>0.981561</td>\n",
              "      <td>0.981447</td>\n",
              "      <td>0.981421</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.834549</td>\n",
              "      <td>0.802303</td>\n",
              "      <td>0.839923</td>\n",
              "      <td>0.806526</td>\n",
              "      <td>0.826104</td>\n",
              "      <td>0.833013</td>\n",
              "      <td>0.802687</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.796083</td>\n",
              "      <td>0.826421</td>\n",
              "      <td>0.816761</td>\n",
              "      <td>0.015868</td>\n",
              "      <td>71</td>\n",
              "      <td>0.924711</td>\n",
              "      <td>0.925607</td>\n",
              "      <td>0.924754</td>\n",
              "      <td>0.925394</td>\n",
              "      <td>0.925863</td>\n",
              "      <td>0.925436</td>\n",
              "      <td>0.926332</td>\n",
              "      <td>0.925308</td>\n",
              "      <td>0.926079</td>\n",
              "      <td>0.925653</td>\n",
              "      <td>0.925514</td>\n",
              "      <td>0.000492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.087781</td>\n",
              "      <td>0.011223</td>\n",
              "      <td>0.052276</td>\n",
              "      <td>0.000583</td>\n",
              "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
              "      <td>gini</td>\n",
              "      <td>42</td>\n",
              "      <td>random</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;function chi2 at 0x7faf2197eb70&gt;</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'clf': DecisionTreeClassifier(class_weight=No...</td>\n",
              "      <td>0.883280</td>\n",
              "      <td>0.786899</td>\n",
              "      <td>0.890114</td>\n",
              "      <td>0.780701</td>\n",
              "      <td>0.856721</td>\n",
              "      <td>0.887777</td>\n",
              "      <td>0.839006</td>\n",
              "      <td>0.827547</td>\n",
              "      <td>0.820158</td>\n",
              "      <td>0.830930</td>\n",
              "      <td>0.840314</td>\n",
              "      <td>0.037303</td>\n",
              "      <td>113</td>\n",
              "      <td>0.899191</td>\n",
              "      <td>0.898719</td>\n",
              "      <td>0.897951</td>\n",
              "      <td>0.898341</td>\n",
              "      <td>0.842931</td>\n",
              "      <td>0.898022</td>\n",
              "      <td>0.845008</td>\n",
              "      <td>0.846032</td>\n",
              "      <td>0.846578</td>\n",
              "      <td>0.844377</td>\n",
              "      <td>0.871715</td>\n",
              "      <td>0.026747</td>\n",
              "      <td>0.842610</td>\n",
              "      <td>0.794626</td>\n",
              "      <td>0.848752</td>\n",
              "      <td>0.790019</td>\n",
              "      <td>0.811516</td>\n",
              "      <td>0.846833</td>\n",
              "      <td>0.818426</td>\n",
              "      <td>0.809597</td>\n",
              "      <td>0.786866</td>\n",
              "      <td>0.807220</td>\n",
              "      <td>0.815648</td>\n",
              "      <td>0.022034</td>\n",
              "      <td>72</td>\n",
              "      <td>0.848867</td>\n",
              "      <td>0.848569</td>\n",
              "      <td>0.848057</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>0.809410</td>\n",
              "      <td>0.848057</td>\n",
              "      <td>0.808642</td>\n",
              "      <td>0.809623</td>\n",
              "      <td>0.812105</td>\n",
              "      <td>0.808778</td>\n",
              "      <td>0.829034</td>\n",
              "      <td>0.019343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.094351</td>\n",
              "      <td>0.004778</td>\n",
              "      <td>0.055624</td>\n",
              "      <td>0.004322</td>\n",
              "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
              "      <td>gini</td>\n",
              "      <td>42</td>\n",
              "      <td>random</td>\n",
              "      <td>6</td>\n",
              "      <td>&lt;function chi2 at 0x7faf2197eb70&gt;</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'clf': DecisionTreeClassifier(class_weight=No...</td>\n",
              "      <td>0.881333</td>\n",
              "      <td>0.794939</td>\n",
              "      <td>0.893739</td>\n",
              "      <td>0.804949</td>\n",
              "      <td>0.899048</td>\n",
              "      <td>0.898314</td>\n",
              "      <td>0.770400</td>\n",
              "      <td>0.775795</td>\n",
              "      <td>0.834018</td>\n",
              "      <td>0.764106</td>\n",
              "      <td>0.831667</td>\n",
              "      <td>0.053675</td>\n",
              "      <td>117</td>\n",
              "      <td>0.926336</td>\n",
              "      <td>0.916263</td>\n",
              "      <td>0.915367</td>\n",
              "      <td>0.915165</td>\n",
              "      <td>0.925340</td>\n",
              "      <td>0.915251</td>\n",
              "      <td>0.915892</td>\n",
              "      <td>0.916630</td>\n",
              "      <td>0.927437</td>\n",
              "      <td>0.915181</td>\n",
              "      <td>0.918886</td>\n",
              "      <td>0.004944</td>\n",
              "      <td>0.848369</td>\n",
              "      <td>0.802303</td>\n",
              "      <td>0.850288</td>\n",
              "      <td>0.808829</td>\n",
              "      <td>0.850672</td>\n",
              "      <td>0.857965</td>\n",
              "      <td>0.797313</td>\n",
              "      <td>0.796161</td>\n",
              "      <td>0.825269</td>\n",
              "      <td>0.834485</td>\n",
              "      <td>0.827165</td>\n",
              "      <td>0.023130</td>\n",
              "      <td>53</td>\n",
              "      <td>0.863456</td>\n",
              "      <td>0.861067</td>\n",
              "      <td>0.860939</td>\n",
              "      <td>0.860299</td>\n",
              "      <td>0.863413</td>\n",
              "      <td>0.860257</td>\n",
              "      <td>0.859873</td>\n",
              "      <td>0.861281</td>\n",
              "      <td>0.864699</td>\n",
              "      <td>0.860561</td>\n",
              "      <td>0.861585</td>\n",
              "      <td>0.001572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.105337</td>\n",
              "      <td>0.005594</td>\n",
              "      <td>0.056486</td>\n",
              "      <td>0.007310</td>\n",
              "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
              "      <td>gini</td>\n",
              "      <td>42</td>\n",
              "      <td>random</td>\n",
              "      <td>8</td>\n",
              "      <td>&lt;function chi2 at 0x7faf2197eb70&gt;</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'clf': DecisionTreeClassifier(class_weight=No...</td>\n",
              "      <td>0.818488</td>\n",
              "      <td>0.769216</td>\n",
              "      <td>0.814125</td>\n",
              "      <td>0.767361</td>\n",
              "      <td>0.821368</td>\n",
              "      <td>0.827879</td>\n",
              "      <td>0.761288</td>\n",
              "      <td>0.743066</td>\n",
              "      <td>0.773823</td>\n",
              "      <td>0.786854</td>\n",
              "      <td>0.788347</td>\n",
              "      <td>0.028335</td>\n",
              "      <td>132</td>\n",
              "      <td>0.980977</td>\n",
              "      <td>0.981498</td>\n",
              "      <td>0.981194</td>\n",
              "      <td>0.981385</td>\n",
              "      <td>0.981547</td>\n",
              "      <td>0.981339</td>\n",
              "      <td>0.981833</td>\n",
              "      <td>0.981429</td>\n",
              "      <td>0.981561</td>\n",
              "      <td>0.981447</td>\n",
              "      <td>0.981421</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.826488</td>\n",
              "      <td>0.809597</td>\n",
              "      <td>0.833013</td>\n",
              "      <td>0.809597</td>\n",
              "      <td>0.824184</td>\n",
              "      <td>0.835317</td>\n",
              "      <td>0.802687</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799155</td>\n",
              "      <td>0.802995</td>\n",
              "      <td>0.814304</td>\n",
              "      <td>0.013337</td>\n",
              "      <td>76</td>\n",
              "      <td>0.924711</td>\n",
              "      <td>0.925607</td>\n",
              "      <td>0.924754</td>\n",
              "      <td>0.925394</td>\n",
              "      <td>0.925863</td>\n",
              "      <td>0.925436</td>\n",
              "      <td>0.926332</td>\n",
              "      <td>0.925308</td>\n",
              "      <td>0.926079</td>\n",
              "      <td>0.925653</td>\n",
              "      <td>0.925514</td>\n",
              "      <td>0.000492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.091204</td>\n",
              "      <td>0.004080</td>\n",
              "      <td>0.053764</td>\n",
              "      <td>0.002011</td>\n",
              "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
              "      <td>entropy</td>\n",
              "      <td>42</td>\n",
              "      <td>best</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;function chi2 at 0x7faf2197eb70&gt;</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'clf': DecisionTreeClassifier(class_weight=No...</td>\n",
              "      <td>0.880058</td>\n",
              "      <td>0.769356</td>\n",
              "      <td>0.891405</td>\n",
              "      <td>0.756139</td>\n",
              "      <td>0.859392</td>\n",
              "      <td>0.892768</td>\n",
              "      <td>0.837834</td>\n",
              "      <td>0.829657</td>\n",
              "      <td>0.823056</td>\n",
              "      <td>0.828021</td>\n",
              "      <td>0.836769</td>\n",
              "      <td>0.044576</td>\n",
              "      <td>116</td>\n",
              "      <td>0.899191</td>\n",
              "      <td>0.898719</td>\n",
              "      <td>0.897951</td>\n",
              "      <td>0.898341</td>\n",
              "      <td>0.842931</td>\n",
              "      <td>0.898022</td>\n",
              "      <td>0.845008</td>\n",
              "      <td>0.846032</td>\n",
              "      <td>0.846578</td>\n",
              "      <td>0.844377</td>\n",
              "      <td>0.871715</td>\n",
              "      <td>0.026747</td>\n",
              "      <td>0.840691</td>\n",
              "      <td>0.785029</td>\n",
              "      <td>0.847985</td>\n",
              "      <td>0.779655</td>\n",
              "      <td>0.811900</td>\n",
              "      <td>0.848752</td>\n",
              "      <td>0.818426</td>\n",
              "      <td>0.810365</td>\n",
              "      <td>0.787634</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.813690</td>\n",
              "      <td>0.024254</td>\n",
              "      <td>81</td>\n",
              "      <td>0.848867</td>\n",
              "      <td>0.848569</td>\n",
              "      <td>0.848057</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>0.809410</td>\n",
              "      <td>0.848057</td>\n",
              "      <td>0.808642</td>\n",
              "      <td>0.809623</td>\n",
              "      <td>0.812105</td>\n",
              "      <td>0.808778</td>\n",
              "      <td>0.829034</td>\n",
              "      <td>0.019343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.107017</td>\n",
              "      <td>0.006003</td>\n",
              "      <td>0.051849</td>\n",
              "      <td>0.000768</td>\n",
              "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
              "      <td>entropy</td>\n",
              "      <td>42</td>\n",
              "      <td>best</td>\n",
              "      <td>6</td>\n",
              "      <td>&lt;function chi2 at 0x7faf2197eb70&gt;</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'clf': DecisionTreeClassifier(class_weight=No...</td>\n",
              "      <td>0.884847</td>\n",
              "      <td>0.794654</td>\n",
              "      <td>0.900998</td>\n",
              "      <td>0.784638</td>\n",
              "      <td>0.902904</td>\n",
              "      <td>0.898959</td>\n",
              "      <td>0.784579</td>\n",
              "      <td>0.776160</td>\n",
              "      <td>0.791349</td>\n",
              "      <td>0.767367</td>\n",
              "      <td>0.828649</td>\n",
              "      <td>0.056380</td>\n",
              "      <td>122</td>\n",
              "      <td>0.926336</td>\n",
              "      <td>0.916263</td>\n",
              "      <td>0.915367</td>\n",
              "      <td>0.915165</td>\n",
              "      <td>0.925340</td>\n",
              "      <td>0.915251</td>\n",
              "      <td>0.915892</td>\n",
              "      <td>0.916630</td>\n",
              "      <td>0.927437</td>\n",
              "      <td>0.915181</td>\n",
              "      <td>0.918886</td>\n",
              "      <td>0.004944</td>\n",
              "      <td>0.847217</td>\n",
              "      <td>0.802687</td>\n",
              "      <td>0.852207</td>\n",
              "      <td>0.801919</td>\n",
              "      <td>0.852207</td>\n",
              "      <td>0.857582</td>\n",
              "      <td>0.804990</td>\n",
              "      <td>0.796929</td>\n",
              "      <td>0.797619</td>\n",
              "      <td>0.836790</td>\n",
              "      <td>0.825015</td>\n",
              "      <td>0.024786</td>\n",
              "      <td>58</td>\n",
              "      <td>0.863456</td>\n",
              "      <td>0.861067</td>\n",
              "      <td>0.860939</td>\n",
              "      <td>0.860299</td>\n",
              "      <td>0.863413</td>\n",
              "      <td>0.860257</td>\n",
              "      <td>0.859873</td>\n",
              "      <td>0.861281</td>\n",
              "      <td>0.864699</td>\n",
              "      <td>0.860561</td>\n",
              "      <td>0.861585</td>\n",
              "      <td>0.001572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.147538</td>\n",
              "      <td>0.005816</td>\n",
              "      <td>0.057624</td>\n",
              "      <td>0.007771</td>\n",
              "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
              "      <td>entropy</td>\n",
              "      <td>42</td>\n",
              "      <td>best</td>\n",
              "      <td>8</td>\n",
              "      <td>&lt;function chi2 at 0x7faf2197eb70&gt;</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'clf': DecisionTreeClassifier(class_weight=No...</td>\n",
              "      <td>0.822813</td>\n",
              "      <td>0.753979</td>\n",
              "      <td>0.825605</td>\n",
              "      <td>0.773465</td>\n",
              "      <td>0.825008</td>\n",
              "      <td>0.825359</td>\n",
              "      <td>0.744803</td>\n",
              "      <td>0.745876</td>\n",
              "      <td>0.760184</td>\n",
              "      <td>0.816834</td>\n",
              "      <td>0.789393</td>\n",
              "      <td>0.034622</td>\n",
              "      <td>130</td>\n",
              "      <td>0.980977</td>\n",
              "      <td>0.981498</td>\n",
              "      <td>0.981194</td>\n",
              "      <td>0.981385</td>\n",
              "      <td>0.981547</td>\n",
              "      <td>0.981339</td>\n",
              "      <td>0.981833</td>\n",
              "      <td>0.981429</td>\n",
              "      <td>0.981561</td>\n",
              "      <td>0.981447</td>\n",
              "      <td>0.981421</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.829175</td>\n",
              "      <td>0.803071</td>\n",
              "      <td>0.838772</td>\n",
              "      <td>0.809213</td>\n",
              "      <td>0.828023</td>\n",
              "      <td>0.837236</td>\n",
              "      <td>0.796929</td>\n",
              "      <td>0.801919</td>\n",
              "      <td>0.798771</td>\n",
              "      <td>0.829109</td>\n",
              "      <td>0.817222</td>\n",
              "      <td>0.015864</td>\n",
              "      <td>69</td>\n",
              "      <td>0.924711</td>\n",
              "      <td>0.925607</td>\n",
              "      <td>0.924754</td>\n",
              "      <td>0.925394</td>\n",
              "      <td>0.925863</td>\n",
              "      <td>0.925436</td>\n",
              "      <td>0.926332</td>\n",
              "      <td>0.925308</td>\n",
              "      <td>0.926079</td>\n",
              "      <td>0.925653</td>\n",
              "      <td>0.925514</td>\n",
              "      <td>0.000492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.089261</td>\n",
              "      <td>0.011051</td>\n",
              "      <td>0.051828</td>\n",
              "      <td>0.000640</td>\n",
              "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
              "      <td>entropy</td>\n",
              "      <td>42</td>\n",
              "      <td>random</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;function chi2 at 0x7faf2197eb70&gt;</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{'clf': DecisionTreeClassifier(class_weight=No...</td>\n",
              "      <td>0.880201</td>\n",
              "      <td>0.786043</td>\n",
              "      <td>0.890407</td>\n",
              "      <td>0.780585</td>\n",
              "      <td>0.858282</td>\n",
              "      <td>0.892855</td>\n",
              "      <td>0.839006</td>\n",
              "      <td>0.828462</td>\n",
              "      <td>0.820651</td>\n",
              "      <td>0.805703</td>\n",
              "      <td>0.838221</td>\n",
              "      <td>0.039218</td>\n",
              "      <td>114</td>\n",
              "      <td>0.899191</td>\n",
              "      <td>0.898719</td>\n",
              "      <td>0.897951</td>\n",
              "      <td>0.898341</td>\n",
              "      <td>0.842931</td>\n",
              "      <td>0.898022</td>\n",
              "      <td>0.845008</td>\n",
              "      <td>0.846032</td>\n",
              "      <td>0.846578</td>\n",
              "      <td>0.844377</td>\n",
              "      <td>0.871715</td>\n",
              "      <td>0.026747</td>\n",
              "      <td>0.840691</td>\n",
              "      <td>0.793858</td>\n",
              "      <td>0.849136</td>\n",
              "      <td>0.790787</td>\n",
              "      <td>0.811900</td>\n",
              "      <td>0.848752</td>\n",
              "      <td>0.818426</td>\n",
              "      <td>0.810365</td>\n",
              "      <td>0.786482</td>\n",
              "      <td>0.795315</td>\n",
              "      <td>0.814573</td>\n",
              "      <td>0.022890</td>\n",
              "      <td>74</td>\n",
              "      <td>0.848867</td>\n",
              "      <td>0.848569</td>\n",
              "      <td>0.848057</td>\n",
              "      <td>0.848228</td>\n",
              "      <td>0.809410</td>\n",
              "      <td>0.848057</td>\n",
              "      <td>0.808642</td>\n",
              "      <td>0.809623</td>\n",
              "      <td>0.812105</td>\n",
              "      <td>0.808778</td>\n",
              "      <td>0.829034</td>\n",
              "      <td>0.019343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  mean_train_Accuracy  std_train_Accuracy\n",
              "0       0.094254      0.004465  ...             0.829034            0.019343\n",
              "1       0.107457      0.005159  ...             0.861585            0.001572\n",
              "2       0.140714      0.005217  ...             0.925514            0.000492\n",
              "3       0.087781      0.011223  ...             0.829034            0.019343\n",
              "4       0.094351      0.004778  ...             0.861585            0.001572\n",
              "5       0.105337      0.005594  ...             0.925514            0.000492\n",
              "6       0.091204      0.004080  ...             0.829034            0.019343\n",
              "7       0.107017      0.006003  ...             0.861585            0.001572\n",
              "8       0.147538      0.005816  ...             0.925514            0.000492\n",
              "9       0.089261      0.011051  ...             0.829034            0.019343\n",
              "\n",
              "[10 rows x 63 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v94Y1ko2w95n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "1348f31a-4c45-4fe7-b91a-8b1a8464fe60"
      },
      "source": [
        "result[result.rank_test_AUC == 1][['mean_train_AUC', 'std_train_AUC','mean_test_AUC', 'std_test_AUC']]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_AUC</th>\n",
              "      <th>std_train_AUC</th>\n",
              "      <th>mean_test_AUC</th>\n",
              "      <th>std_test_AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>0.921701</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>0.902703</td>\n",
              "      <td>0.014056</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean_train_AUC  std_train_AUC  mean_test_AUC  std_test_AUC\n",
              "125        0.921701       0.000456       0.902703      0.014056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjkUNieaxVX4",
        "colab_type": "text"
      },
      "source": [
        "Verirficando o desempenho do modelo em relação a overfitting (com relação a AUC e acurácia)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKW9z4gqxW7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "575f6fa3-4a8d-4d00-9af9-b0875fd2dd76"
      },
      "source": [
        "# Training score much higher than test score.\n",
        "# The standard deviation of the test score is large.\n",
        "result_auc = result[['mean_train_AUC', 'std_train_AUC','mean_test_AUC', 'std_test_AUC']]\n",
        "result_auc"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_AUC</th>\n",
              "      <th>std_train_AUC</th>\n",
              "      <th>mean_test_AUC</th>\n",
              "      <th>std_test_AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.871715</td>\n",
              "      <td>0.026747</td>\n",
              "      <td>0.837376</td>\n",
              "      <td>0.044736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.918886</td>\n",
              "      <td>0.004944</td>\n",
              "      <td>0.829567</td>\n",
              "      <td>0.055405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.981421</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.789025</td>\n",
              "      <td>0.034058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.871715</td>\n",
              "      <td>0.026747</td>\n",
              "      <td>0.840314</td>\n",
              "      <td>0.037303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.918886</td>\n",
              "      <td>0.004944</td>\n",
              "      <td>0.831667</td>\n",
              "      <td>0.053675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.981421</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.788347</td>\n",
              "      <td>0.028335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.871715</td>\n",
              "      <td>0.026747</td>\n",
              "      <td>0.836769</td>\n",
              "      <td>0.044576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.918886</td>\n",
              "      <td>0.004944</td>\n",
              "      <td>0.828649</td>\n",
              "      <td>0.056380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.981421</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.789393</td>\n",
              "      <td>0.034622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.871715</td>\n",
              "      <td>0.026747</td>\n",
              "      <td>0.838221</td>\n",
              "      <td>0.039218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.918886</td>\n",
              "      <td>0.004944</td>\n",
              "      <td>0.829506</td>\n",
              "      <td>0.052672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.981421</td>\n",
              "      <td>0.000216</td>\n",
              "      <td>0.792129</td>\n",
              "      <td>0.023735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.830957</td>\n",
              "      <td>0.005571</td>\n",
              "      <td>0.825865</td>\n",
              "      <td>0.012820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.851978</td>\n",
              "      <td>0.003134</td>\n",
              "      <td>0.843579</td>\n",
              "      <td>0.018459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.869553</td>\n",
              "      <td>0.001245</td>\n",
              "      <td>0.863675</td>\n",
              "      <td>0.012044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.833458</td>\n",
              "      <td>0.008372</td>\n",
              "      <td>0.827389</td>\n",
              "      <td>0.013044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.855549</td>\n",
              "      <td>0.002556</td>\n",
              "      <td>0.845086</td>\n",
              "      <td>0.019370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.869661</td>\n",
              "      <td>0.001248</td>\n",
              "      <td>0.863753</td>\n",
              "      <td>0.012196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.836352</td>\n",
              "      <td>0.010974</td>\n",
              "      <td>0.828800</td>\n",
              "      <td>0.015430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.857522</td>\n",
              "      <td>0.001799</td>\n",
              "      <td>0.845790</td>\n",
              "      <td>0.020576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.869364</td>\n",
              "      <td>0.001353</td>\n",
              "      <td>0.863576</td>\n",
              "      <td>0.012169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.837433</td>\n",
              "      <td>0.012110</td>\n",
              "      <td>0.830013</td>\n",
              "      <td>0.015256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.858362</td>\n",
              "      <td>0.002093</td>\n",
              "      <td>0.845348</td>\n",
              "      <td>0.020508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.868809</td>\n",
              "      <td>0.001233</td>\n",
              "      <td>0.863081</td>\n",
              "      <td>0.012260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.860930</td>\n",
              "      <td>0.021477</td>\n",
              "      <td>0.848425</td>\n",
              "      <td>0.024355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.886285</td>\n",
              "      <td>0.002336</td>\n",
              "      <td>0.866395</td>\n",
              "      <td>0.027703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.896228</td>\n",
              "      <td>0.001034</td>\n",
              "      <td>0.886416</td>\n",
              "      <td>0.013785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.861118</td>\n",
              "      <td>0.021667</td>\n",
              "      <td>0.848325</td>\n",
              "      <td>0.024819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.887256</td>\n",
              "      <td>0.001874</td>\n",
              "      <td>0.866932</td>\n",
              "      <td>0.027724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.896339</td>\n",
              "      <td>0.000882</td>\n",
              "      <td>0.886590</td>\n",
              "      <td>0.013945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.864689</td>\n",
              "      <td>0.023360</td>\n",
              "      <td>0.849840</td>\n",
              "      <td>0.026888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0.895091</td>\n",
              "      <td>0.001214</td>\n",
              "      <td>0.870282</td>\n",
              "      <td>0.030143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>0.906806</td>\n",
              "      <td>0.000648</td>\n",
              "      <td>0.895675</td>\n",
              "      <td>0.013948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>0.864672</td>\n",
              "      <td>0.023305</td>\n",
              "      <td>0.849836</td>\n",
              "      <td>0.026855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.895608</td>\n",
              "      <td>0.000993</td>\n",
              "      <td>0.869145</td>\n",
              "      <td>0.031089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>0.906798</td>\n",
              "      <td>0.000667</td>\n",
              "      <td>0.895199</td>\n",
              "      <td>0.014297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0.866955</td>\n",
              "      <td>0.024395</td>\n",
              "      <td>0.850732</td>\n",
              "      <td>0.027773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0.900805</td>\n",
              "      <td>0.000932</td>\n",
              "      <td>0.872677</td>\n",
              "      <td>0.031403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>0.913799</td>\n",
              "      <td>0.000557</td>\n",
              "      <td>0.899695</td>\n",
              "      <td>0.014085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>0.867097</td>\n",
              "      <td>0.024526</td>\n",
              "      <td>0.850898</td>\n",
              "      <td>0.027885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>0.900900</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.872879</td>\n",
              "      <td>0.031172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>0.914078</td>\n",
              "      <td>0.000571</td>\n",
              "      <td>0.900479</td>\n",
              "      <td>0.013663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>0.867156</td>\n",
              "      <td>0.024546</td>\n",
              "      <td>0.850998</td>\n",
              "      <td>0.027881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>0.900936</td>\n",
              "      <td>0.000825</td>\n",
              "      <td>0.872623</td>\n",
              "      <td>0.031140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>0.914021</td>\n",
              "      <td>0.000598</td>\n",
              "      <td>0.899876</td>\n",
              "      <td>0.014017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>0.867181</td>\n",
              "      <td>0.024538</td>\n",
              "      <td>0.850967</td>\n",
              "      <td>0.027869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>0.900932</td>\n",
              "      <td>0.000882</td>\n",
              "      <td>0.872762</td>\n",
              "      <td>0.031312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.914055</td>\n",
              "      <td>0.000603</td>\n",
              "      <td>0.899567</td>\n",
              "      <td>0.014288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>0.869931</td>\n",
              "      <td>0.025143</td>\n",
              "      <td>0.850817</td>\n",
              "      <td>0.029349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>0.906513</td>\n",
              "      <td>0.001018</td>\n",
              "      <td>0.873875</td>\n",
              "      <td>0.032109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>0.921524</td>\n",
              "      <td>0.000443</td>\n",
              "      <td>0.902170</td>\n",
              "      <td>0.014512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>0.869976</td>\n",
              "      <td>0.025192</td>\n",
              "      <td>0.851108</td>\n",
              "      <td>0.029151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>0.906630</td>\n",
              "      <td>0.000970</td>\n",
              "      <td>0.873919</td>\n",
              "      <td>0.032159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>0.921701</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>0.902703</td>\n",
              "      <td>0.014056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>0.870008</td>\n",
              "      <td>0.025219</td>\n",
              "      <td>0.851000</td>\n",
              "      <td>0.029299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>0.906693</td>\n",
              "      <td>0.000997</td>\n",
              "      <td>0.873969</td>\n",
              "      <td>0.031974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.921668</td>\n",
              "      <td>0.000503</td>\n",
              "      <td>0.902298</td>\n",
              "      <td>0.014167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>0.870019</td>\n",
              "      <td>0.025227</td>\n",
              "      <td>0.850995</td>\n",
              "      <td>0.029243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>0.906575</td>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.873905</td>\n",
              "      <td>0.032002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>0.921702</td>\n",
              "      <td>0.000518</td>\n",
              "      <td>0.902073</td>\n",
              "      <td>0.014422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean_train_AUC  std_train_AUC  mean_test_AUC  std_test_AUC\n",
              "0          0.871715       0.026747       0.837376      0.044736\n",
              "1          0.918886       0.004944       0.829567      0.055405\n",
              "2          0.981421       0.000216       0.789025      0.034058\n",
              "3          0.871715       0.026747       0.840314      0.037303\n",
              "4          0.918886       0.004944       0.831667      0.053675\n",
              "5          0.981421       0.000216       0.788347      0.028335\n",
              "6          0.871715       0.026747       0.836769      0.044576\n",
              "7          0.918886       0.004944       0.828649      0.056380\n",
              "8          0.981421       0.000216       0.789393      0.034622\n",
              "9          0.871715       0.026747       0.838221      0.039218\n",
              "10         0.918886       0.004944       0.829506      0.052672\n",
              "11         0.981421       0.000216       0.792129      0.023735\n",
              "12         0.830957       0.005571       0.825865      0.012820\n",
              "13         0.851978       0.003134       0.843579      0.018459\n",
              "14         0.869553       0.001245       0.863675      0.012044\n",
              "15         0.833458       0.008372       0.827389      0.013044\n",
              "16         0.855549       0.002556       0.845086      0.019370\n",
              "17         0.869661       0.001248       0.863753      0.012196\n",
              "18         0.836352       0.010974       0.828800      0.015430\n",
              "19         0.857522       0.001799       0.845790      0.020576\n",
              "20         0.869364       0.001353       0.863576      0.012169\n",
              "21         0.837433       0.012110       0.830013      0.015256\n",
              "22         0.858362       0.002093       0.845348      0.020508\n",
              "23         0.868809       0.001233       0.863081      0.012260\n",
              "24         0.860930       0.021477       0.848425      0.024355\n",
              "25         0.886285       0.002336       0.866395      0.027703\n",
              "26         0.896228       0.001034       0.886416      0.013785\n",
              "27         0.861118       0.021667       0.848325      0.024819\n",
              "28         0.887256       0.001874       0.866932      0.027724\n",
              "29         0.896339       0.000882       0.886590      0.013945\n",
              "..              ...            ...            ...           ...\n",
              "102        0.864689       0.023360       0.849840      0.026888\n",
              "103        0.895091       0.001214       0.870282      0.030143\n",
              "104        0.906806       0.000648       0.895675      0.013948\n",
              "105        0.864672       0.023305       0.849836      0.026855\n",
              "106        0.895608       0.000993       0.869145      0.031089\n",
              "107        0.906798       0.000667       0.895199      0.014297\n",
              "108        0.866955       0.024395       0.850732      0.027773\n",
              "109        0.900805       0.000932       0.872677      0.031403\n",
              "110        0.913799       0.000557       0.899695      0.014085\n",
              "111        0.867097       0.024526       0.850898      0.027885\n",
              "112        0.900900       0.000809       0.872879      0.031172\n",
              "113        0.914078       0.000571       0.900479      0.013663\n",
              "114        0.867156       0.024546       0.850998      0.027881\n",
              "115        0.900936       0.000825       0.872623      0.031140\n",
              "116        0.914021       0.000598       0.899876      0.014017\n",
              "117        0.867181       0.024538       0.850967      0.027869\n",
              "118        0.900932       0.000882       0.872762      0.031312\n",
              "119        0.914055       0.000603       0.899567      0.014288\n",
              "120        0.869931       0.025143       0.850817      0.029349\n",
              "121        0.906513       0.001018       0.873875      0.032109\n",
              "122        0.921524       0.000443       0.902170      0.014512\n",
              "123        0.869976       0.025192       0.851108      0.029151\n",
              "124        0.906630       0.000970       0.873919      0.032159\n",
              "125        0.921701       0.000456       0.902703      0.014056\n",
              "126        0.870008       0.025219       0.851000      0.029299\n",
              "127        0.906693       0.000997       0.873969      0.031974\n",
              "128        0.921668       0.000503       0.902298      0.014167\n",
              "129        0.870019       0.025227       0.850995      0.029243\n",
              "130        0.906575       0.001028       0.873905      0.032002\n",
              "131        0.921702       0.000518       0.902073      0.014422\n",
              "\n",
              "[132 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wGtdLnexnc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a19d33b-1e14-43fb-9a57-e277e935931c"
      },
      "source": [
        "result_acc = result[['mean_train_Accuracy', 'std_train_Accuracy','mean_test_Accuracy', 'std_test_Accuracy']]\n",
        "result_acc"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_Accuracy</th>\n",
              "      <th>std_train_Accuracy</th>\n",
              "      <th>mean_test_Accuracy</th>\n",
              "      <th>std_test_Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.829034</td>\n",
              "      <td>0.019343</td>\n",
              "      <td>0.813959</td>\n",
              "      <td>0.024112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.861585</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.824900</td>\n",
              "      <td>0.024614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.925514</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.816761</td>\n",
              "      <td>0.015868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.829034</td>\n",
              "      <td>0.019343</td>\n",
              "      <td>0.815648</td>\n",
              "      <td>0.022034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.861585</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.827165</td>\n",
              "      <td>0.023130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.925514</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.814304</td>\n",
              "      <td>0.013337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.829034</td>\n",
              "      <td>0.019343</td>\n",
              "      <td>0.813690</td>\n",
              "      <td>0.024254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.861585</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.825015</td>\n",
              "      <td>0.024786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.925514</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.817222</td>\n",
              "      <td>0.015864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.829034</td>\n",
              "      <td>0.019343</td>\n",
              "      <td>0.814573</td>\n",
              "      <td>0.022890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.861585</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.826474</td>\n",
              "      <td>0.022385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.925514</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.817145</td>\n",
              "      <td>0.010471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.803683</td>\n",
              "      <td>0.001027</td>\n",
              "      <td>0.803632</td>\n",
              "      <td>0.008734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.812718</td>\n",
              "      <td>0.005549</td>\n",
              "      <td>0.811924</td>\n",
              "      <td>0.012885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.810900</td>\n",
              "      <td>0.001770</td>\n",
              "      <td>0.810465</td>\n",
              "      <td>0.008349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.803709</td>\n",
              "      <td>0.000979</td>\n",
              "      <td>0.803709</td>\n",
              "      <td>0.008813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.813942</td>\n",
              "      <td>0.006180</td>\n",
              "      <td>0.813268</td>\n",
              "      <td>0.013384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.811775</td>\n",
              "      <td>0.001012</td>\n",
              "      <td>0.811617</td>\n",
              "      <td>0.008611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.803717</td>\n",
              "      <td>0.000974</td>\n",
              "      <td>0.803709</td>\n",
              "      <td>0.008813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.811417</td>\n",
              "      <td>0.005486</td>\n",
              "      <td>0.811041</td>\n",
              "      <td>0.012848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.811425</td>\n",
              "      <td>0.001004</td>\n",
              "      <td>0.811080</td>\n",
              "      <td>0.008654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.803709</td>\n",
              "      <td>0.000979</td>\n",
              "      <td>0.803709</td>\n",
              "      <td>0.008813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.812692</td>\n",
              "      <td>0.006807</td>\n",
              "      <td>0.810964</td>\n",
              "      <td>0.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.810977</td>\n",
              "      <td>0.001011</td>\n",
              "      <td>0.810465</td>\n",
              "      <td>0.008789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.817406</td>\n",
              "      <td>0.010927</td>\n",
              "      <td>0.813613</td>\n",
              "      <td>0.014899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.830104</td>\n",
              "      <td>0.009389</td>\n",
              "      <td>0.823557</td>\n",
              "      <td>0.014428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.847610</td>\n",
              "      <td>0.002037</td>\n",
              "      <td>0.833423</td>\n",
              "      <td>0.012996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.817440</td>\n",
              "      <td>0.010987</td>\n",
              "      <td>0.813844</td>\n",
              "      <td>0.014677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.832062</td>\n",
              "      <td>0.007888</td>\n",
              "      <td>0.822827</td>\n",
              "      <td>0.013387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.845465</td>\n",
              "      <td>0.000928</td>\n",
              "      <td>0.832693</td>\n",
              "      <td>0.012380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.822396</td>\n",
              "      <td>0.014839</td>\n",
              "      <td>0.812615</td>\n",
              "      <td>0.020174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0.841165</td>\n",
              "      <td>0.004842</td>\n",
              "      <td>0.828509</td>\n",
              "      <td>0.016226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>0.853087</td>\n",
              "      <td>0.001448</td>\n",
              "      <td>0.835573</td>\n",
              "      <td>0.015033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>0.825404</td>\n",
              "      <td>0.016692</td>\n",
              "      <td>0.815072</td>\n",
              "      <td>0.020503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.839676</td>\n",
              "      <td>0.006567</td>\n",
              "      <td>0.828471</td>\n",
              "      <td>0.016237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>0.852878</td>\n",
              "      <td>0.001139</td>\n",
              "      <td>0.835880</td>\n",
              "      <td>0.014819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0.827750</td>\n",
              "      <td>0.018174</td>\n",
              "      <td>0.812462</td>\n",
              "      <td>0.025034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0.842837</td>\n",
              "      <td>0.004886</td>\n",
              "      <td>0.830428</td>\n",
              "      <td>0.013667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>0.862459</td>\n",
              "      <td>0.001090</td>\n",
              "      <td>0.842944</td>\n",
              "      <td>0.017533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>0.827865</td>\n",
              "      <td>0.018303</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.025125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>0.842726</td>\n",
              "      <td>0.004880</td>\n",
              "      <td>0.830236</td>\n",
              "      <td>0.015364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>0.862514</td>\n",
              "      <td>0.001019</td>\n",
              "      <td>0.843904</td>\n",
              "      <td>0.017176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>0.827997</td>\n",
              "      <td>0.018455</td>\n",
              "      <td>0.812961</td>\n",
              "      <td>0.025056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>0.842867</td>\n",
              "      <td>0.004768</td>\n",
              "      <td>0.830275</td>\n",
              "      <td>0.015490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>0.862476</td>\n",
              "      <td>0.001070</td>\n",
              "      <td>0.842982</td>\n",
              "      <td>0.017126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>0.828006</td>\n",
              "      <td>0.018463</td>\n",
              "      <td>0.812922</td>\n",
              "      <td>0.025071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>0.842803</td>\n",
              "      <td>0.004698</td>\n",
              "      <td>0.830160</td>\n",
              "      <td>0.015545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0.862472</td>\n",
              "      <td>0.000905</td>\n",
              "      <td>0.842560</td>\n",
              "      <td>0.017533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>0.828833</td>\n",
              "      <td>0.019143</td>\n",
              "      <td>0.813191</td>\n",
              "      <td>0.025014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>0.855621</td>\n",
              "      <td>0.000952</td>\n",
              "      <td>0.829200</td>\n",
              "      <td>0.021472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>0.867876</td>\n",
              "      <td>0.000582</td>\n",
              "      <td>0.847436</td>\n",
              "      <td>0.016992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>0.828829</td>\n",
              "      <td>0.019139</td>\n",
              "      <td>0.813306</td>\n",
              "      <td>0.024774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>0.854666</td>\n",
              "      <td>0.003351</td>\n",
              "      <td>0.829123</td>\n",
              "      <td>0.021539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>0.868102</td>\n",
              "      <td>0.000734</td>\n",
              "      <td>0.847743</td>\n",
              "      <td>0.016529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>0.828838</td>\n",
              "      <td>0.019148</td>\n",
              "      <td>0.813613</td>\n",
              "      <td>0.024744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>0.854423</td>\n",
              "      <td>0.003682</td>\n",
              "      <td>0.830736</td>\n",
              "      <td>0.020923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0.867911</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>0.847013</td>\n",
              "      <td>0.016385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>0.828825</td>\n",
              "      <td>0.019135</td>\n",
              "      <td>0.813498</td>\n",
              "      <td>0.024675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>0.854380</td>\n",
              "      <td>0.003750</td>\n",
              "      <td>0.830045</td>\n",
              "      <td>0.021503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>0.867928</td>\n",
              "      <td>0.000884</td>\n",
              "      <td>0.847013</td>\n",
              "      <td>0.016268</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean_train_Accuracy  ...  std_test_Accuracy\n",
              "0               0.829034  ...           0.024112\n",
              "1               0.861585  ...           0.024614\n",
              "2               0.925514  ...           0.015868\n",
              "3               0.829034  ...           0.022034\n",
              "4               0.861585  ...           0.023130\n",
              "5               0.925514  ...           0.013337\n",
              "6               0.829034  ...           0.024254\n",
              "7               0.861585  ...           0.024786\n",
              "8               0.925514  ...           0.015864\n",
              "9               0.829034  ...           0.022890\n",
              "10              0.861585  ...           0.022385\n",
              "11              0.925514  ...           0.010471\n",
              "12              0.803683  ...           0.008734\n",
              "13              0.812718  ...           0.012885\n",
              "14              0.810900  ...           0.008349\n",
              "15              0.803709  ...           0.008813\n",
              "16              0.813942  ...           0.013384\n",
              "17              0.811775  ...           0.008611\n",
              "18              0.803717  ...           0.008813\n",
              "19              0.811417  ...           0.012848\n",
              "20              0.811425  ...           0.008654\n",
              "21              0.803709  ...           0.008813\n",
              "22              0.812692  ...           0.013500\n",
              "23              0.810977  ...           0.008789\n",
              "24              0.817406  ...           0.014899\n",
              "25              0.830104  ...           0.014428\n",
              "26              0.847610  ...           0.012996\n",
              "27              0.817440  ...           0.014677\n",
              "28              0.832062  ...           0.013387\n",
              "29              0.845465  ...           0.012380\n",
              "..                   ...  ...                ...\n",
              "102             0.822396  ...           0.020174\n",
              "103             0.841165  ...           0.016226\n",
              "104             0.853087  ...           0.015033\n",
              "105             0.825404  ...           0.020503\n",
              "106             0.839676  ...           0.016237\n",
              "107             0.852878  ...           0.014819\n",
              "108             0.827750  ...           0.025034\n",
              "109             0.842837  ...           0.013667\n",
              "110             0.862459  ...           0.017533\n",
              "111             0.827865  ...           0.025125\n",
              "112             0.842726  ...           0.015364\n",
              "113             0.862514  ...           0.017176\n",
              "114             0.827997  ...           0.025056\n",
              "115             0.842867  ...           0.015490\n",
              "116             0.862476  ...           0.017126\n",
              "117             0.828006  ...           0.025071\n",
              "118             0.842803  ...           0.015545\n",
              "119             0.862472  ...           0.017533\n",
              "120             0.828833  ...           0.025014\n",
              "121             0.855621  ...           0.021472\n",
              "122             0.867876  ...           0.016992\n",
              "123             0.828829  ...           0.024774\n",
              "124             0.854666  ...           0.021539\n",
              "125             0.868102  ...           0.016529\n",
              "126             0.828838  ...           0.024744\n",
              "127             0.854423  ...           0.020923\n",
              "128             0.867911  ...           0.016385\n",
              "129             0.828825  ...           0.024675\n",
              "130             0.854380  ...           0.021503\n",
              "131             0.867928  ...           0.016268\n",
              "\n",
              "[132 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O433ObpcxUrY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "a9ed4186-8d46-4080-d787-d0c28714ab79"
      },
      "source": [
        "result[result.rank_test_Accuracy == 1][['mean_train_Accuracy', 'std_train_Accuracy','mean_test_Accuracy', 'std_test_Accuracy']]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_Accuracy</th>\n",
              "      <th>std_train_Accuracy</th>\n",
              "      <th>mean_test_Accuracy</th>\n",
              "      <th>std_test_Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>0.870363</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>0.848818</td>\n",
              "      <td>0.016177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_train_Accuracy  ...  std_test_Accuracy\n",
              "68             0.870363  ...           0.016177\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqn6RJcPzVD0",
        "colab_type": "text"
      },
      "source": [
        "Testando o modelo acima com o conjunto treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc1gEwHrzYHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "cb575cbe-d13d-446c-8a01-0208f159ddfc"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# final model\n",
        "predict = best_model.predict(X_test)\n",
        "print(roc_auc_score(y_test, predict))\n",
        "print(accuracy_score(y_test, predict))\n",
        "print(confusion_matrix(y_test,predict))\n",
        "print(classification_report(y_test,predict))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7695127267287096\n",
            "0.8662674650698603\n",
            "[[4728  217]\n",
            " [ 654  914]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92      4945\n",
            "           1       0.81      0.58      0.68      1568\n",
            "\n",
            "    accuracy                           0.87      6513\n",
            "   macro avg       0.84      0.77      0.80      6513\n",
            "weighted avg       0.86      0.87      0.86      6513\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmGS4mwK0c_d",
        "colab_type": "text"
      },
      "source": [
        "**Analisando a feature importance do modelo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKtAJTkf06Ep",
        "colab_type": "text"
      },
      "source": [
        "Com base nos resultados acima, após a otimização do modelo (usando o GridSearchCV), nota-se que a RandomForest apresentou o melhor resultado quando comparada a uma árvore de decisão simples (foi o modelo vencedor pela GridSearchCV). De fato este resultado era esperado.\n",
        "\n",
        "Sabe-se também que uma RandomForest consiste na técnica de bagging utilizando-se várias ávores de decisão, logo a combinação de vários resultados dessas ávores geralmente produzem um resultado final melhor que o de apenas uma.\n",
        "\n",
        "Uma análise inicial a ser feita é a de feature importante. Primeiramente será mostrado o resultado gerado pela própria RandomForest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKoyL_tfZ3Ri",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "3357aed4-5ba9-4d4c-9e3a-8f390cca6d6b"
      },
      "source": [
        "%matplotlib inline\n",
        "#!pip3 install eli5\n",
        "#!pip3 install skater\n",
        "\n",
        "import eli5 \n",
        "\n",
        "fs = best_model.best_estimator_.steps[1][1] # SelectKBest\n",
        "support = fs.get_support(indices=False)\n",
        "selected_columns = X_train.columns[support]\n",
        "\n",
        "# # Exibe a feature importance da RandomForest.\n",
        "for name, value in zip(selected_columns.to_list(), best_model.best_params_['clf'].feature_importances_):\n",
        "  print(name, value)\n",
        "\n",
        "# Utilizando a biblioteca ELI5, exibe a feature importance da RandomForest.\n",
        "eli5.show_weights(best_model.best_params_['clf'], show_feature_values=True, feature_names=selected_columns.to_list())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "workclass 0.09276902300197479\n",
            "fnlwgt 0.1916404622960708\n",
            "education 0.0691661254504158\n",
            "education_num 0.2087449363666952\n",
            "occupation 0.0286553232838529\n",
            "race 0.12782775787455983\n",
            "capital_loss 0.21721125249814452\n",
            "hours_per_week 0.06398511922828627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.2172\n",
              "                \n",
              "                    &plusmn; 0.0849\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                capital_loss\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.55%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.2087\n",
              "                \n",
              "                    &plusmn; 0.3344\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                education_num\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 81.68%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1916\n",
              "                \n",
              "                    &plusmn; 0.3092\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                fnlwgt\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 86.20%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1278\n",
              "                \n",
              "                    &plusmn; 0.1533\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                race\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 88.97%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0928\n",
              "                \n",
              "                    &plusmn; 0.0773\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                workclass\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.02%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0692\n",
              "                \n",
              "                    &plusmn; 0.0602\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                education\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.50%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0640\n",
              "                \n",
              "                    &plusmn; 0.0464\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                hours_per_week\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.16%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0287\n",
              "                \n",
              "                    &plusmn; 0.0750\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                occupation\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uahBXpOw1BmN",
        "colab_type": "text"
      },
      "source": [
        "Para contrapor o resultado de feature importance da RandomForest, abaixo ela será calculada utilizando a biblioteca Skater."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtMGj6RpzJhf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "9464bf35-ebc0-461d-d108-1609fc1c479a"
      },
      "source": [
        "from skater.core.explanations import Interpretation\n",
        "from skater.model import InMemoryModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Utilizando a biblioteca Skater, exibe a feature importance.\n",
        "X_temp1 = best_model.best_estimator_.steps[0][1].transform(X_train)\n",
        "X_temp2 = best_model.best_estimator_.steps[1][1].transform(X_temp1)\n",
        "\n",
        "interpreter = Interpretation(training_data=X_temp2, training_labels=y_train, \n",
        "                               feature_names=selected_columns.to_list())\n",
        "\n",
        "im_model = InMemoryModel(best_model.best_params_['clf'].predict_proba, examples=X_temp2, target_names=['$50K or less', 'More than $50K'])\n",
        "\n",
        "plots = interpreter.feature_importance.plot_feature_importance(im_model, ascending=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-15 05:09:11,712 - skater.core.explanations - WARNING - Progress bars slow down runs by 10-20%. For slightly \n",
            "faster runs, do progress_bar=False\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[8/8] features ████████████████████ Time elapsed: 3 seconds"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbgAAAD8CAYAAAAFdLF9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG3xJREFUeJzt3XuUXVWB5/Hvz/AoSRAIaBat0QJE\nEoiQNhUUEFRkRF2KUYOx5WEiQ4T2kW4njE6LCDi2NjC6fI0YbUhwbAUUhR5bBXnGAEmqyJMEUAOO\nIisSo0iQBAO/+ePusq9lpd5V99ap32etu+qcffbZZ5+9bvixzzn3XtkmIiKiap7V6A5EREQMhwRc\nRERUUgIuIiIqKQEXERGVlICLiIhKSsBFREQlJeAiIqKSEnAREVFJCbiIiKik3RrdgbHsgAMOcGtr\na6O7ERExqnR0dGyx/dze6iXgGqi1tZX29vZGdyMiYlSR9Iu+1MslyoiIqKQEXEREVFICLiIiKikB\nFxERlZSAi4iISspTlA20cfN2Zly2odHdiIgYUR0LDx+R42QGFxERlZSAi4iISkrARUREJQ15wEma\nK+mLQ9zmLEmH161fLOmkoTxGRERUy2iZwc0C/hxwti+w/eMG9iciIppcvwNO0umSVkhaLekrksZJ\nmifpAUkrgOPq6i6WNLtufVvd8oclrZO0RtKnS9nZklaWsu9I2kvSscApwKXlmIfUtyvptZJWlbau\nkLRnKX9I0kWS7inbpvRwTheWfW+TtEnSB0t5q6T1dfUWSrqwLN8m6bOS2iVtlDRT0nWSfirpf/Z3\nXCMiYmj1K+AkTQXmAMfZng48DZwOXEQt2F5J3Uyrh3beALwFeLnto4BLyqbrbM8sZRuBs2zfCdwA\nnGd7uu2f17XTAiwG5th+KbWPPZxbd6gttl8GfBlY2Eu3pgAnA0cDH5e0e2/nATxluw24HLgeeB8w\nDZgraf9dnPv8EortO7dt7cMhIiJiIPo7g3stMANYKWl1Wf9H4Dbbj9p+Cri6D+2cBFxp+48Atjv/\nSz9N0lJJ64DTgCN6aecw4EHbD5T1JcAJdduvK387gNZe2vq+7R22twC/ASb14TxuKH/XAffafsT2\nDmATMLm7HWwvst1mu223CRP7cIiIiBiI/gacgCVlJjXd9mHAhT3U39l5DEnPAvbopf3FwPvLbOwi\noKWf/etqR/n7NL1/qH1H3XJn/T/3v+jan859numy/zN9OF5ERAyj/gbczcBsSc8DkDQRWAW8StL+\n5bLeqXX1H6I244PafbTOy343AfMk7VXXDsDewCOlndPq2nm8bOvqfqBV0ovL+hnA7f08p55sBp5X\nzm1P4E1D2HZERAyjfgWc7Q3A+cCNktZSC6oDqc3i7gKWUbt31umr1MJvDXAM8ERp54fULu+1l0ud\nnffHPgYsL+3cV9fOt4DzysMkh9T1ZzswD7i2XNZ8htr9sCFh+0/AxcCKcq739bxHREQ0C9ludB/G\nrPGTp3nKgmsa3Y2IiBE12O+ilNRRHvDr0Wj5HFxERES/jKkHISTNAxZ0KV5m+32N6M/USS20j9C3\nakdEjDVjKuBsXwlc2eh+RETE8MslyoiIqKQEXEREVFICLiIiKikBFxERlZSAi4iISkrARUREJSXg\nIiKikhJwERFRSQm4iIiopARcRERUUgIuIiIqaUx9F2Wz2bh5OzMu29DobkTECBrsT8VE32UGFxER\nlZSAi4iIShozASfpg5I2SvpGD3W2DcFx5kr6m8G2ExERgzOW7sH9PXCS7V8N83HmAuuBXw/zcSIi\nogdjYgYn6XLgYOAHkh6TdIWk2yRtkvTBbup/SdIpZfm7kq4oy++R9Mmy/DFJ90v6iaRvSlooaTbQ\nBnxD0mpJzx65s4yIiHpjIuBsn0NtRvUa4LPAFOBk4Gjg45J277LLUuD4svx8oPOxp+OBOyTNBN4O\nHAW8gVqoYfvbQDtwmu3ptp8ctpOKiIgejYmA68b3be+wvQX4DTCpy/alwPGSDgc2AJslHQgcA9wJ\nHAdcb3u77ceBf+/rgSXNl9QuqX3ntq1DcjIREfHXxmrA7ahbfpou9yJtPwzsC7weuINa4L0D2FYC\nbcBsL7LdZrtttwkTB9NURET0YKwGXF/cDfwD/xlwC8tfgGXAmyW1SJoAvKluv8eBvUeyoxER8dcS\ncLu2FNjN9s+Ae4CJpQzbK4EbgLXAD4B1wGNlv8XA5XnIJCKisWS70X0YlSRNsL1N0l7UZnnzbd/T\nnzbGT57mKQuuGZ4ORkRTyld1DZ6kDtttvdUbS5+DG2qLykMoLcCS/oZbREQMrwTcANl+V6P7EBER\nu5aAa6Cpk1poz+WKiIhhkYdMIiKikhJwERFRSQm4iIiopARcRERUUgIuIiIqKQEXERGVlICLiIhK\nSsBFREQlJeAiIqKSEnAREVFJCbiIiKikBFxERFRSAi4iIiopvybQQBs3b2fGZRsa3Y2IysmPigZk\nBhcRERWVgIuIiEpKwEVERCUl4HZBNRmfiIhRKv8BryOpVdL9kq4C1gP/Kqld0r2SLqqrN1PSnZLW\nSFohaW9J4yRdKmmlpLWS3tu4M4mIiDxF+dcOBd5t+25JE21vlTQOuFnSkcB9wNXAHNsrJT0HeBI4\nC3jM9kxJewLLJN1o+8H6xiXNB+YD7LHvgSN5XhERY0oC7q/9wvbdZfkdJZB2Aw4EDgcMPGJ7JYDt\nPwBIeh1wpKTZZd99qIXlXwSc7UXAIoDxk6d5mM8lImLMSsD9tScAJB0ELARm2v6dpMVASw/7CfiA\n7R8NfxcjIqI3uQe3a8+hFnaPSZoEvKGU3w8cKGkmQLn/thvwI+BcSbuX8pdIGt+AfkdEBJnB7ZLt\nNZJWUbvn9ktgWSl/StIc4AuSnk3t/ttJwNeAVuAeSQIeBWY1ou8REZGA+wu2HwKm1a3P3UW9lcAr\nutn0T+UVERENlkuUERFRSZnBNdDUSS2050thIyKGRWZwERFRSQm4iIiopARcRERUUgIuIiIqKQEX\nERGVlICLiIhKSsBFREQlJeAiIqKSEnAREVFJCbiIiKikBFxERFRSAi4iIiopARcREZWUXxNooI2b\ntzPjsg2N7kZEQ3TklzRimGUGFxERlZSAi4iISkrARUREJY3qgJP0N5K+XZanS3pjH/Z5taT/28P2\nuZK+OJT9jIiIkTeqA872r23PLqvTgV4DLiIixoaGBpykMyWtlbRG0tclvVnSckmrJP1Y0qRS78Ky\n/S5JP5V0dilvlbRe0h7AxcAcSaslzZF0dKm/StKdkg4bQP9aJd1S+nizpBeW8lPLcddIuqOUHSFp\nRTn+WkmH7qLN+ZLaJbXv3LZ1oEMXERG9aNjHBCQdAZwPHGt7i6SJgIFX2Lak/wr8d+C/lV2OBF4B\njAdWSfp+Z1u2n5J0AdBm+/2l/ecAx9veKekk4J+Bt/ezm18AltheIuk9wOeBWcAFwMm2H5a0b6l7\nDvA5298ogTuuuwZtLwIWAYyfPM397E9ERPRRIz8HdyJwre0tALa3SnopcLWkA4E9gAfr6l9v+0ng\nSUm3AkcDq3tofx9gSZlJGdh9AH08BnhbWf46cElZXgYslnQNcF0puwv4qKQXANfZ/ukAjhcREUOk\n2e7BfQH4ou2XAu8FWuq2dZ3t9Db7+QRwq+1pwJu7tDUots+hNvucDHRI2t/2vwGnAE8C/yHpxKE6\nXkRE9F8jA+4W4FRJ+wOUS5T7AA+X7e/uUv8tklpK/VcDK7tsfxzYu269vq25A+zjncA7y/JpwNLS\n10NsL7d9AfAoMFnSwcAm258Hrqd2STUiIhqkYQFn+17gk8DtktYAnwEuBK6V1AFs6bLLWuBW4G7g\nE7Z/3WX7rcDhnQ+ZULuc+ClJqxj4pdgPAPMkrQXOABaU8kslrZO0nloIrgHeAayXtBqYBlw1wGNG\nRMQQkN38zzlIuhDYZvuyRvdlKI2fPM1TFlzT6G5ENES+izIGSlKH7bbe6uXLlhto6qQW2vOPPCJi\nWIyKgLN94VC3KWke/3nJsdMy2+8b6mNFRMTIGxUBNxxsXwlc2eh+RETE8Gi2jwlEREQMiQRcRERU\nUgIuIiIqKQEXERGVlICLiIhKSsBFREQlJeAiIqKSEnAREVFJCbiIiKikBFxERFRSAi4iIippzH4X\nZTPYuHk7My7b0OhuRAy7/DRONEJmcBERUUkJuIiIqKQxEXCSHpJ0QB/rXihp4XD3KSIihlflA07S\nuEb3ISIiRl5TB5yk8yR9sCx/VtItZflESd+Q9HeS1klaL+lf6vbbJul/SVoDHFNX/mxJP5B0dlk/\nU9JaSWskfb2b458taWXZ/h1Je5XyU8sx10i6o5QdIWmFpNWlzUOHdXAiIqJHTR1wwFLg+LLcBkyQ\ntHspewD4F+BEYDowU9KsUnc8sNz2UbZ/UsomAP8OfNP2VyUdAZwPnGj7KGBBN8e/zvbMsn0jcFYp\nvwA4uZSfUsrOAT5ne3rp66+G4PwjImKAmj3gOoAZkp4D7ADuohYexwO/B26z/ajtncA3gBPKfk8D\n3+nS1vXAlbavKusnAtfa3gJge2s3x58maamkdcBpwBGlfBmwuMwEOy+B3gX8k6QPAy+y/WR3JyRp\nvqR2Se07t3V3yIiIGApNHXC2/wQ8CMwF7qQ2o3sN8GLgoR523W776S5ly4DXS1I/urAYeL/tlwIX\nAS2lX+dQm/1NBjok7W/736jN5p4E/kPSibs4p0W222y37TZhYj+6EhER/dHUAVcsBRYCd5Tlc4BV\nwArgVZIOKA+S/B1wew/tXAD8DvhSWb8FOFXS/gCSukubvYFHymXR0zoLJR1ie7ntC4BHgcmSDgY2\n2f48tdnikQM94YiIGLzREnAHAnfZ3gxsB5bafgT4CHArsAbosH19L20tAJ4t6RLb9wKfBG4vD6N8\nppv6HwOWU5v93VdXfmnnwy3UZpZrgHcA6yWtBqYBV3VtLCIiRo5sN7oPY9b4ydM8ZcE1je5GxLDL\nV3XFUJLUYbutt3qjYQYXERHRb/my5QaaOqmF9vyfbUTEsMgMLiIiKikBFxERlZSAi4iISkrARURE\nJSXgIiKikhJwERFRSQm4iIiopARcRERUUgIuIiIqKQEXERGVlICLiIhKSsBFREQlJeAiIqKS8msC\nDbRx83ZmXLah0d2IistvscVYlRlcRERUUgIuIiIqadQHnKS5kr44xG3OknR43frFkk4aymNERMTw\nGvUBN0xmAX8OONsX2P5xA/sTERH91PQBJ+l0SSskrZb0FUnjJM2T9ICkFcBxdXUXS5pdt76tbvnD\nktZJWiPp06XsbEkrS9l3JO0l6VjgFODScsxD6tuV9FpJq0pbV0jas5Q/JOkiSfeUbVNGaIgiIqIb\nTR1wkqYCc4DjbE8HngZOBy6iFmyvpG6m1UM7bwDeArzc9lHAJWXTdbZnlrKNwFm27wRuAM6zPd32\nz+vaaQEWA3Nsv5TaU6jn1h1qi+2XAV8GFg78zCMiYrCaOuCA1wIzgJWSVpf1fwRus/2o7aeAq/vQ\nzknAlbb/CGB7aymfJmmppHXAacARvbRzGPCg7QfK+hLghLrt15W/HUBrdw1Imi+pXVL7zm1bu6sS\nERFDoNkDTsCSMpOabvsw4MIe6u+knJOkZwF79NL+YuD9ZTZ2EdAyyP7uKH+fZhefMbS9yHab7bbd\nJkwc5OEiImJXmj3gbgZmS3oegKSJwCrgVZL2l7Q7cGpd/Yeozfigdh9t97J8EzBP0l517QDsDTxS\n2jmtrp3Hy7au7gdaJb24rJ8B3D7w04uIiOHS1AFnewNwPnCjpLXUgupAarO4u4Bl1O6ddfoqtfBb\nAxwDPFHa+SG1+2rt5VJn5/2xjwHLSzv31bXzLeC88jDJIXX92Q7MA64tlzWfAS4fynOOiIihIduN\n7sOYNX7yNE9ZcE2juxEVl6/qiqqR1GG7rbd6TT2Di4iIGKgEXEREVFJ+TaCBpk5qoT2XjyIihkVm\ncBERUUkJuIiIqKQEXEREVFICLiIiKikBFxERlZSAi4iISkrARUREJSXgIiKikhJwERFRSQm4iIio\npARcRERUUgIuIiIqKV+23EAbN29nxmUbGt2NUSe/bxYRfZEZXEREVFICLiIiKikB1w1J0yW9sW79\nFEkfaWSfIiKifxJw3ZsO/DngbN9g+9MN7E9ERPRTUwWcpA9JWl9e/1DKzpS0VtIaSV8vZZMkfbeU\nrZF0rKRWSevr2loo6cKyfJukz0laXdo+upQfLekuSask3SnpMEl7ABcDc0r9OZLmSvpi2adV0i2l\nTzdLemEpXyzp86WdTZJmj+jgRUTEX2iapyglzQDmAS8HBCyXtBI4HzjW9hZJE0v1zwO3236rpHHA\nBGC/Xg6xl+3pkk4ArgCmAfcBx9veKekk4J9tv13SBUCb7feXvs2ta+cLwBLbSyS9p/RlVtl2IPBK\nYApwA/DtAQ9IREQMStMEHLVg+K7tJwAkXQe0Adfa3gJge2upeyJwZil7GnhMUm8B981S/w5Jz5G0\nL7A3sETSoYCB3fvQz2OAt5XlrwOX1G37nu1ngA2SJnW3s6T5wHyAPfY9sA+Hi4iIgWiqS5SDtJO/\nPJ+WLtvdzfongFttTwPe3M0+/bWjblndVbC9yHab7bbdJkzsrkpERAyBZgq4pcAsSXtJGg+8FWgH\nTpW0P0DdJcqbgXNL2ThJ+wCbgedJ2l/SnsCburQ/p9R/JfCY7ceAfYCHy/a5dXUfpza7686dwDvL\n8mml3xER0WSaJuBs3wMsBlYAy4Gv2V4GfBK4XdIa4DOl+gLgNZLWAR3A4bb/RO3hkBXATdTur9Xb\nLmkVcDlwVim7BPhUKa+/XHsrcHjnQyZd2vkAME/SWuCM0peIiGgysrteuaseSbcBC223N7ov9cZP\nnuYpC65pdDdGnXxVV8TYJqnDdltv9ZpmBhcRETGUmukpymFj+9WN7kNERIysMRFwzWrqpBbac7kt\nImJY5BJlRERUUgIuIiIqKQEXERGVlICLiIhKSsBFREQlJeAiIqKSEnAREVFJCbiIiKikBFxERFRS\nAi4iIiopARcREZWUgIuIiErKly030MbN25lx2YZGd2PE5HfcImIkZQYXERGVlICLiIhKSsBFREQl\n9RpwklolrR+JzoxmGaeIiObSkBmcpBF7uGUkjxUREc2jrwE3TtJXJd0r6UZJz5Y0XdLdktZK+q6k\n/QAk3SaprSwfIOmhsjxX0g2SbgFulnSgpDskrZa0XtLxuzq4pG2SPluOf7Ok55byQyT9UFKHpKWS\nppTyxZIul7QcuGQXba6TtK9qfivpzFJ+laT/ImmcpEslrSzn+N66fc+rK7+om7YPlrRK0sw+jm9E\nRAyxvgbcocCXbB8B/B54O3AV8GHbRwLrgI/3oZ2XAbNtvwp4F/Aj29OBo4DVPew3Hmgvx7+97liL\ngA/YngEsBP533T4vAI61/aFdtLkMOA44AtgEdAbsMcCdwFnAY7ZnAjOBsyUdJOl1ZTyOBqYDMySd\n0NmopMOA7wBzba/selBJ8yW1S2rfuW1rD6ccERGD0dfLdw/a7gygDuAQYF/bt5eyJcC1fWjnJtud\n/1VfCVwhaXfge3Xtd+cZ4Oqy/H+A6yRNAI4FrpXUWW/Pun2utf10D20uBU4AfgF8GZgv6fnA72w/\nUYLsSEmzS/19qAXb68prVSmfUMr/H/Bc4Hrgbba7/YCb7UXUgpnxk6e5h/5FRMQg9HUGt6Nu+Wlg\n3x7q7qxrt6XLtic6F2zfQS1gHgYWd14i7COXY/ze9vS619TujrULd1CbtR0P3AY8CsymFnwAojY7\n7Gz7INs3lvJP1ZW/2Pa/ln0eoxZ0r+zHuURExDAY6EMmjwG/q7tvdga1S4cADwEzyvJsdkHSi4DN\ntr8KfI3a5cue+tnZ1ruAn9j+A/CgpFNLe5J0VF9PwPYvgQOAQ21vAn5C7TLnHaXKj4BzywwTSS+R\nNL6Uv6fMIJH0fEnPK/s8BbwVOFPSu/ral4iIGHqDecLw3cDlkvaidg9rXim/DLhG0nzg+z3s/2rg\nPEl/ArYBPc3gngCOlnQ+8BtgTik/DfhyKd8d+Bawph/nsBwYV5aXAp+iFnRQC91W4B7VroE+Csyy\nfaOkqcBd5dLoNuB0ajNbyuXNNwE3Sdpm+4Z+9CciIoaI7Oa/DVSCYkKj+zHUxk+e5ikLrml0N0ZM\nvosyIoaCpA7bbb3VyzeZREREJTXVh6DL59b27FJ8xmBmb5LmAQu6FC+z/b6BtjlUpk5qoT2zmoiI\nYdFUAWf75cPQ5pXAlUPdbkRENLdcooyIiEpKwEVERCUl4CIiopIScBERUUkJuIiIqKRR8UHvqpL0\nOHB/o/vR5A4AtjS6E00uY9S7jFHvRtMYvcj2c3ur1FQfExiD7u/Lp/HHMkntGaOeZYx6lzHqXRXH\nKJcoIyKikhJwERFRSQm4xlrU6A6MAhmj3mWMepcx6l3lxigPmURERCVlBhcREZWUgBsmkl4v6X5J\nP5P0kW627ynp6rJ9uaTWum3/o5TfL+nkkez3SBno+EhqlfSkpNXldflI932k9GGMTpB0j6SdkmZ3\n2fZuST8tr3ePXK9H1iDH6Om691Flf5i4D2P0IUkbJK2VdLOkF9VtG93vI9t5DfGL2q+E/xw4GNiD\n2q+MH96lzt8Dl5fldwJXl+XDS/09gYNKO+MafU5NND6twPpGn0OTjFErcCRwFTC7rnwisKn83a8s\n79foc2qmMSrbtjX6HJpkjF4D7FWWz637tzbq30eZwQ2Po4Gf2d5k+yngW8BbutR5C7CkLH8beK0k\nlfJv2d5h+0HgZ6W9KhnM+IwVvY6R7YdsrwWe6bLvycBNtrfa/h1wE/D6kej0CBvMGI0VfRmjW23/\nsazeDbygLI/691ECbng8H/hl3fqvSlm3dWzvBB4D9u/jvqPdYMYH4CBJqyTdLun44e5sgwzmfTAW\n3kMw+PNskdQu6W5Js4a2a02jv2N0FvCDAe7bdPJNJjHaPAK80PZvJc0AvifpCNt/aHTHYtR5ke2H\nJR0M3CJpne2fN7pTjSLpdKANeFWj+zJUMoMbHg8Dk+vWX1DKuq0jaTdgH+C3fdx3tBvw+JRLt78F\nsN1B7f7CS4a9xyNvMO+DsfAegkGep+2Hy99NwG3A3w5l55pEn8ZI0knAR4FTbO/oz77NLAE3PFYC\nh0o6SNIe1B6S6PqU1g1A51NJs4FbXLuzewPwzvIU4UHAocCKEer3SBnw+Eh6rqRxAOX/vA+ldvO7\navoyRrvyI+B1kvaTtB/wulJWNQMeozI2e5blA4DjgA3D1tPG6XWMJP0t8BVq4fabuk2j/33U6Kdc\nqvoC3gg8QG2G8dFSdjG1NxFAC3AttYdIVgAH1+370bLf/cAbGn0uzTQ+wNuBe4HVwD3Amxt9Lg0c\no5nU7os8QW32f2/dvu8pY/czYF6jz6XZxgg4FlhH7anCdcBZjT6XBo7Rj4HN5d/UauCGqryP8k0m\nERFRSblEGRERlZSAi4iISkrARUREJSXgIiKikhJwERFRSQm4iIiopARcRERUUgIuIiIq6f8DtD6z\nCFj57ocAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBLG8glU1RtA",
        "colab_type": "text"
      },
      "source": [
        "É interessante notar que no resultado acima, as features possem pesos diferentes daqueles gerados pela RandomForest. Isso pode sugerir que o modelo pode não estar otimizado para seu melhor desempenho, visto que a RandomForest está tratando as features com pesos diferentes daqueles sugeridos pela outra biblioteca. Com isso, a seguir novos modelos e hiperparâmetros serão avaliados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i0uHWw921zF",
        "colab_type": "text"
      },
      "source": [
        "**Personalizando hipermarâmetros em busca de uma melhoria no modelo**\n",
        "\n",
        "A seguir, serão construídos modelos utilizando-se a técnica de Bagging e Pasting utilizando árvores de decisão, o que é similar à RandomForest.\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gL1gLPD3YDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "\n",
        "# instantiate a bagging object (model,size,samples,bootstrap,rnd)\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(random_state=seed, splitter='random'), \n",
        "                            n_estimators=200,\n",
        "                            bootstrap=True, \n",
        "                            oob_score=True,\n",
        "                            random_state=seed)\n",
        "\n",
        "pas_clf = BaggingClassifier(DecisionTreeClassifier(random_state=seed, splitter='random'), \n",
        "                            n_estimators=200,\n",
        "                            bootstrap=False, \n",
        "                            oob_score=False,\n",
        "                            random_state=seed)\n",
        "\n",
        "# The full pipeline as a step in another pipeline with an estimator as the final step\n",
        "pipe_bag = Pipeline(steps = [('full_pipeline', full_pipeline_preprocessing),\n",
        "                         (\"fs\", SelectKBest()),\n",
        "                         (\"clf\", bag_clf)])\n",
        "\n",
        "pipe_pas = Pipeline(steps = [('full_pipeline', full_pipeline_preprocessing),\n",
        "                         (\"fs\", SelectKBest()),\n",
        "                         (\"clf\", pas_clf)])\n",
        "\n",
        "search_space =  {\n",
        "                  \"fs__score_func\": [chi2],\n",
        "                  \"fs__k\": [4, 6, 8]\n",
        "                 }\n",
        "              \n",
        "\n",
        "grid_bag = GridSearchCV(estimator=pipe_bag, \n",
        "                    param_grid=search_space,\n",
        "                    cv=kfold,\n",
        "                    scoring=scoring,\n",
        "                    return_train_score=True,\n",
        "                    n_jobs=-1,\n",
        "                    refit=\"AUC\")\n",
        "\n",
        "\n",
        "grid_pas = GridSearchCV(estimator=pipe_bag, \n",
        "                    param_grid=search_space,\n",
        "                    cv=kfold,\n",
        "                    scoring=scoring,\n",
        "                    return_train_score=True,\n",
        "                    n_jobs=-1,\n",
        "                    refit=\"AUC\")\n",
        "\n",
        "# Treine os modelos novamente caso não encontre-os.\n",
        "try:\n",
        "  model_bag = pickle.load(open('pipe-bag.pkl', 'rb'))\n",
        "except:\n",
        "  model_bag = grid_bag.fit(X_train, y_train)\n",
        "  with open('pipe-bag.pkl', 'wb') as file:\n",
        "    pickle.dump(model_bag, file)\n",
        "\n",
        "try:\n",
        "  model_pas = pickle.load(open('pipe-pas.pkl', 'rb'))\n",
        "except:\n",
        "  model_pas = grid_pas.fit(X_train, y_train)\n",
        "  with open('pipe-pas.pkl', 'wb') as file:\n",
        "    pickle.dump(model_pas, file)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "madhj8Nf9ZYe",
        "colab_type": "text"
      },
      "source": [
        "Para avaliar ambos os modelos acima, será utilizada a mesma metodologia usada no caso da RandomForest apresentada inicialmente.\n",
        "\n",
        "Primeiramente para a técnica de bagging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97fYNscm7vI8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "02d9d45d-9e56-4d7f-a845-566996949f6c"
      },
      "source": [
        "# Para a técnica de bagging.\n",
        "result_bag = pd.DataFrame(model_bag.cv_results_)\n",
        "result_bag[result_bag.rank_test_AUC == 1][['mean_train_AUC', 'std_train_AUC','mean_test_AUC', 'std_test_AUC']]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_AUC</th>\n",
              "      <th>std_train_AUC</th>\n",
              "      <th>mean_test_AUC</th>\n",
              "      <th>std_test_AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.979087</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.877549</td>\n",
              "      <td>0.011415</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_train_AUC  std_train_AUC  mean_test_AUC  std_test_AUC\n",
              "2        0.979087       0.000222       0.877549      0.011415"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KsMzFn9-WFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f2bd8fbe-e618-43e9-84f4-517c252d0aed"
      },
      "source": [
        "result_acc = result_bag[['mean_train_Accuracy', 'std_train_Accuracy','mean_test_Accuracy', 'std_test_Accuracy']]\n",
        "result_acc"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_Accuracy</th>\n",
              "      <th>std_train_Accuracy</th>\n",
              "      <th>mean_test_Accuracy</th>\n",
              "      <th>std_test_Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.829034</td>\n",
              "      <td>0.019343</td>\n",
              "      <td>0.814074</td>\n",
              "      <td>0.023963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.861585</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.826282</td>\n",
              "      <td>0.024127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.925514</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.836571</td>\n",
              "      <td>0.011741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_train_Accuracy  ...  std_test_Accuracy\n",
              "0             0.829034  ...           0.023963\n",
              "1             0.861585  ...           0.024127\n",
              "2             0.925514  ...           0.011741\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEAmPErP2htb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "f31d8739-398d-4b28-dc06-097de1d26f9d"
      },
      "source": [
        "result_bag[result_bag.rank_test_Accuracy == 1][['mean_train_Accuracy', 'std_train_Accuracy','mean_test_Accuracy', 'std_test_Accuracy']]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_Accuracy</th>\n",
              "      <th>std_train_Accuracy</th>\n",
              "      <th>mean_test_Accuracy</th>\n",
              "      <th>std_test_Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.925514</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.836571</td>\n",
              "      <td>0.011741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_train_Accuracy  ...  std_test_Accuracy\n",
              "2             0.925514  ...           0.011741\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aH4H1ch-mqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b82a84b0-e3b4-400c-a201-488556118d8e"
      },
      "source": [
        "# Exibe resultado do OOB\n",
        "print(model_bag.best_estimator_[2].oob_score_)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8430589680589681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZixU3yTAdf7",
        "colab_type": "text"
      },
      "source": [
        "No resultado do OOB, nota-se que a acurácia esperada no conjunto de teste será em torno de 84%. De fato, isto pode ser percebido abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNqF9o-iAPkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "59d2025a-577f-4c8c-c63a-cd425bcdb31a"
      },
      "source": [
        "s"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC =  0.7710282495202327\n",
            "Accuracy =  0.8427759864885613\n",
            "[[4497  448]\n",
            " [ 576  992]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90      4945\n",
            "           1       0.69      0.63      0.66      1568\n",
            "\n",
            "    accuracy                           0.84      6513\n",
            "   macro avg       0.79      0.77      0.78      6513\n",
            "weighted avg       0.84      0.84      0.84      6513\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcmXZH0vASy1",
        "colab_type": "text"
      },
      "source": [
        "No resultado acima, entretanto, nota-se que o overfitting itensificou-se já que a diferença entre tanto a acurácia e da ROC AUC aumentaram entre o conjunto treinamento e teste. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRoeJz0lA1ku",
        "colab_type": "text"
      },
      "source": [
        "Agora será analisado o modelo utilizando pasting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvyZYqqLA4hL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "1dabfbfb-bf38-4d01-ab28-7731b7640635"
      },
      "source": [
        "# Para a técnica de pasting.\n",
        "result_pas = pd.DataFrame(model_pas.cv_results_)\n",
        "result_pas[result_pas.rank_test_AUC == 1][['mean_train_AUC', 'std_train_AUC','mean_test_AUC', 'std_test_AUC']]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_AUC</th>\n",
              "      <th>std_train_AUC</th>\n",
              "      <th>mean_test_AUC</th>\n",
              "      <th>std_test_AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.979087</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>0.877549</td>\n",
              "      <td>0.011415</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_train_AUC  std_train_AUC  mean_test_AUC  std_test_AUC\n",
              "2        0.979087       0.000222       0.877549      0.011415"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsmWljgqBIKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8ad7142d-a8db-46d5-94f1-38cb909b9334"
      },
      "source": [
        "result_acc = result_pas[['mean_train_Accuracy', 'std_train_Accuracy','mean_test_Accuracy', 'std_test_Accuracy']]\n",
        "result_acc"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_Accuracy</th>\n",
              "      <th>std_train_Accuracy</th>\n",
              "      <th>mean_test_Accuracy</th>\n",
              "      <th>std_test_Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.829034</td>\n",
              "      <td>0.019343</td>\n",
              "      <td>0.814074</td>\n",
              "      <td>0.023963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.861585</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.826282</td>\n",
              "      <td>0.024127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.925514</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.836571</td>\n",
              "      <td>0.011741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_train_Accuracy  ...  std_test_Accuracy\n",
              "0             0.829034  ...           0.023963\n",
              "1             0.861585  ...           0.024127\n",
              "2             0.925514  ...           0.011741\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpfyQSRG4DZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "00b858ee-fe21-4ff7-d767-bb3404d81c3b"
      },
      "source": [
        "result_pas[result_pas.rank_test_Accuracy == 1][['mean_train_Accuracy', 'std_train_Accuracy','mean_test_Accuracy', 'std_test_Accuracy']]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_Accuracy</th>\n",
              "      <th>std_train_Accuracy</th>\n",
              "      <th>mean_test_Accuracy</th>\n",
              "      <th>std_test_Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.925514</td>\n",
              "      <td>0.000492</td>\n",
              "      <td>0.836571</td>\n",
              "      <td>0.011741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_train_Accuracy  ...  std_test_Accuracy\n",
              "2             0.925514  ...           0.011741\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5mNDH0oCjmS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "935fe349-aead-4758-8093-c6bff87d7e58"
      },
      "source": [
        "predict_pas = model_pas.predict(X_test)\n",
        "print(\"ROC AUC = \", roc_auc_score(y_test, predict_pas))\n",
        "print(\"Accuracy = \", accuracy_score(y_test, predict_pas))\n",
        "print(confusion_matrix(y_test, predict_pas))\n",
        "print(classification_report(y_test, predict_pas))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC =  0.7710282495202327\n",
            "Accuracy =  0.8427759864885613\n",
            "[[4497  448]\n",
            " [ 576  992]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.91      0.90      4945\n",
            "           1       0.69      0.63      0.66      1568\n",
            "\n",
            "    accuracy                           0.84      6513\n",
            "   macro avg       0.79      0.77      0.78      6513\n",
            "weighted avg       0.84      0.84      0.84      6513\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c_uq0QcDIaX",
        "colab_type": "text"
      },
      "source": [
        "Novamente, o resultado do pasting foi muito similar ao do bagging, com uma piora no overfitting em relação à RandomForest original. Portanto, a tentativa final a seguir será no sentido de tentar melhorar a RandomForest original através de modificações no seu pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91WS3au4DYwT",
        "colab_type": "text"
      },
      "source": [
        "No pipeline original, será alterado o tipo KFold para StratifiedKFold, com o objetivo de melhorar a validação cruzada no exemplo original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76BoG14YD0ht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=num_folds, random_state=seed)\n",
        "\n",
        "pipe = Pipeline(steps = [('full_pipeline', full_pipeline_preprocessing),\n",
        "                         (\"fs\", SelectKBest()),\n",
        "                         (\"clf\", RandomForestClassifier())])\n",
        "\n",
        "# Seach space simplificado para ser mais rápido.\n",
        "search_space = [\n",
        "                {\"clf\":[RandomForestClassifier()],\n",
        "                 \"clf__n_estimators\": [200,],\n",
        "                 \"clf__criterion\": [\"entropy\"],\n",
        "                 \"clf__max_leaf_nodes\": [128],\n",
        "                 \"clf__max_depth\": [8, 32],\n",
        "                 \"clf__bootstrap\": [False],\n",
        "                 \"clf__random_state\": [seed],\n",
        "                 \"fs__score_func\":[chi2],\n",
        "                 \"fs__k\":[8]}]\n",
        "\n",
        "# return_train_score=True\n",
        "# official documentation: \"computing the scores on the training set can be\n",
        "# computationally expensive and is not strictly required to\n",
        "# select the parameters that yield the best generalization performance\".\n",
        "grid = GridSearchCV(estimator=pipe, \n",
        "                    param_grid=search_space,\n",
        "                    cv=skfold,\n",
        "                    scoring=scoring,\n",
        "                    return_train_score=True,\n",
        "                    n_jobs=-1,\n",
        "                    refit=\"AUC\")\n",
        "\n",
        "try:\n",
        "  final_model = pickle.load(open('pipe-final.pkl', 'rb'))\n",
        "except:\n",
        "  final_model = grid.fit(X_train, y_train)\n",
        "  with open('pipe-final.pkl', 'wb') as file:\n",
        "    pickle.dump(final_model, file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhiPL0YlLSbW",
        "colab_type": "text"
      },
      "source": [
        "Analisando os mesmos resultados dos modelos anteriores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbKRnYt4LYOn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "23920507-47b5-4040-f250-9f9cd1107b91"
      },
      "source": [
        "result_final = pd.DataFrame(final_model.cv_results_)\n",
        "result_final[result_final.rank_test_AUC == 1][['mean_train_AUC', 'std_train_AUC','mean_test_AUC', 'std_test_AUC']]"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_AUC</th>\n",
              "      <th>std_train_AUC</th>\n",
              "      <th>mean_test_AUC</th>\n",
              "      <th>std_test_AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.921257</td>\n",
              "      <td>0.000457</td>\n",
              "      <td>0.90218</td>\n",
              "      <td>0.013995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_train_AUC  std_train_AUC  mean_test_AUC  std_test_AUC\n",
              "1        0.921257       0.000457        0.90218      0.013995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYxBUuitLi6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "d9d8bc49-3edf-4071-83c2-d699070dd8dd"
      },
      "source": [
        "result_acc = result_final[['mean_train_Accuracy', 'std_train_Accuracy','mean_test_Accuracy', 'std_test_Accuracy']]\n",
        "result_acc"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_Accuracy</th>\n",
              "      <th>std_train_Accuracy</th>\n",
              "      <th>mean_test_Accuracy</th>\n",
              "      <th>std_test_Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.854316</td>\n",
              "      <td>0.000765</td>\n",
              "      <td>0.837607</td>\n",
              "      <td>0.015154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.868107</td>\n",
              "      <td>0.000902</td>\n",
              "      <td>0.848050</td>\n",
              "      <td>0.017370</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_train_Accuracy  ...  std_test_Accuracy\n",
              "0             0.854316  ...           0.015154\n",
              "1             0.868107  ...           0.017370\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdpSHMzP5sOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "c933eec3-0427-4809-d713-5f9c680cc602"
      },
      "source": [
        "result_final[result_final.rank_test_Accuracy == 1][['mean_train_Accuracy', 'std_train_Accuracy','mean_test_Accuracy', 'std_test_Accuracy']]"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_train_Accuracy</th>\n",
              "      <th>std_train_Accuracy</th>\n",
              "      <th>mean_test_Accuracy</th>\n",
              "      <th>std_test_Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.868107</td>\n",
              "      <td>0.000902</td>\n",
              "      <td>0.84805</td>\n",
              "      <td>0.01737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_train_Accuracy  ...  std_test_Accuracy\n",
              "1             0.868107  ...            0.01737\n",
              "\n",
              "[1 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tsjR6dLLyvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "cb35d55b-c715-431d-b468-28cc23c0b90e"
      },
      "source": [
        "predict_final = final_model.predict(X_test)\n",
        "print(\"ROC AUC = \", roc_auc_score(y_test, predict_final))\n",
        "print(\"Accuracy = \", accuracy_score(y_test, predict_final))\n",
        "print(confusion_matrix(y_test, predict_final))\n",
        "print(classification_report(y_test, predict_final))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC AUC =  0.7703837879944698\n",
            "Accuracy =  0.8662674650698603\n",
            "[[4724  221]\n",
            " [ 650  918]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92      4945\n",
            "           1       0.81      0.59      0.68      1568\n",
            "\n",
            "    accuracy                           0.87      6513\n",
            "   macro avg       0.84      0.77      0.80      6513\n",
            "weighted avg       0.86      0.87      0.86      6513\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXECoUnwL8y_",
        "colab_type": "text"
      },
      "source": [
        "Como se vê acima, o resultado da acurácia no conjunto de teste ficou muito mais próximo que em todos os modelos analisados anteriormente. Logo, o StratifiedKFold ajudou a reduzir o overfitting e melhorou o resultado da RandomForest.\n",
        "\n",
        "Por fim, o melhor modelo obtido é mostrado a seguir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5q-6NiwMbkJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "3f44a3c1-e0bf-4ca4-c6fd-8ffdbadb667d"
      },
      "source": [
        "final_model.best_estimator_"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('full_pipeline',\n",
              "                 FeatureUnion(n_jobs=None,\n",
              "                              transformer_list=[('categorical_pipeline',\n",
              "                                                 Pipeline(memory=None,\n",
              "                                                          steps=[('cat_selector',\n",
              "                                                                  FeatureSelector(feature_names=['workclass',\n",
              "                                                                                                 'education',\n",
              "                                                                                                 'marital_status',\n",
              "                                                                                                 'occupation',\n",
              "                                                                                                 'relationship',\n",
              "                                                                                                 'race',\n",
              "                                                                                                 'sex',\n",
              "                                                                                                 'native_country'])),\n",
              "                                                                 ('cat_transformer',\n",
              "                                                                  CategoricalTransformer(new_features=True))...\n",
              "                 RandomForestClassifier(bootstrap=False, class_weight=None,\n",
              "                                        criterion='entropy', max_depth=32,\n",
              "                                        max_features='auto', max_leaf_nodes=128,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=200, n_jobs=None,\n",
              "                                        oob_score=False, random_state=42,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    }
  ]
}